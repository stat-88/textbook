
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>12.3. Towards Multiple Regression &#8212; Data 88S Textbook</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="12.4. Exercises" href="04_Exercises.html" />
    <link rel="prev" title="12.2. The Distribution of the Estimated Slope" href="02_The_Distribution_of_the_Estimated_Slope.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/data88s_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data 88S Textbook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="http://stat88.org">
   Course Home
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapters
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_01/00_The_Basics.html">
   1. The Basics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/01_Probabilities_as_Proportions.html">
     1.1. Probabilities as Proportions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/02_Exact_Calculation_or_Bound.html">
     1.2. Exact Calculation, or Bound?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/03_Fundamental_Rules.html">
     1.3. Fundamental Rules
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/04_Exercises.html">
     1.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_02/00_Intersections_and_Conditioning.html">
   2. Intersections and Conditioning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/01_The_Chance_of_an_Intersection.html">
     2.1. The Chance of an Intersection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/02_Symmetry_in_Simple_Random_Sampling.html">
     2.2. Symmetry in Simple Random Sampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/03_Bayes_Rule.html">
     2.3. Bayes’ Rule
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/04_Use_and_Interpretation.html">
     2.4. Use and Interpretation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/05_Independence.html">
     2.5. Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/06_Exercises.html">
     2.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_03/00_Random_Counts.html">
   3. Random Counts
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/01_Success_and_Failure.html">
     3.1. Success and Failure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/02_Random_Variables.html">
     3.2. Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/03_The_Binomial_Distribution.html">
     3.3. The Binomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/04_The_Hypergeometric_Distribution.html">
     3.4. The Hypergeometric Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/05_Examples.html">
     3.5. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/06_Exercises.html">
     3.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_04/00_Infinitely_Many_Values.html">
   4. Infinitely Many Values
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/01_Cumulative_Distribution_Function.html">
     4.1. Cumulative Distribution Function (CDF)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/02_Waiting_Times.html">
     4.2. Waiting Times
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/03_Exponential_Approximations.html">
     4.3. Exponential Approximations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/04_The_Poisson_Distribution.html">
     4.4. The Poisson Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/05_Exercises.html">
     4.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_05/00_Expectation.html">
   5. Expectation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/01_Definition.html">
     5.1. Definition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/02_Functions_of_Random_Variables.html">
     5.2. Functions of Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/03_Method_of_Indicators.html">
     5.3. Method of Indicators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/04_Unbiased_Estimators.html">
     5.4. Unbiased Estimators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/05_Conditional_Expectation.html">
     5.5. Conditional Expectation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/06_Expectation_by_Conditioning.html">
     5.6. Expectation by Conditioning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/07_Exercises.html">
     5.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_06/00_Measuring_Variability.html">
   6. Measuring Variability
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/01_Variance_and_Standard_Deviation.html">
     6.1. Variance and Standard Deviation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/02_Simplifying_the_Calculation.html">
     6.2. Simplifying the Calculation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/03_Markovs_Inequality.html">
     6.3. Markov’s Inequality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/04_Chebyshevs_Inequality.html">
     6.4. Chebyshev’s Inequality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/05_Exercises.html">
     6.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_07/00_The_Variance_of_a_Sum.html">
   7. The Variance of a Sum
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/01_Sums_of_Independent_Random_Variables.html">
     7.1. Sums of Independent Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/02_Sampling_Without_Replacement.html">
     7.2. Sampling Without Replacement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/03_The_Law_of_Averages.html">
     7.3. The Law of Averages
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/04_Exercises.html">
     7.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_08/00_Central_Limit_Theorem.html">
   8. Central Limit Theorem
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/01_Distribution_of_a_Sample_Sum.html">
     8.1. The Distribution of a Sample Sum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/02_Standard_Normal_Curve.html">
     8.2. Standard Normal Curve
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/03_Normal_Approximation.html">
     8.3. Normal Approximation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/04_How_Large_is_Large.html">
     8.4. How Large is “Large”?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/05_Exercises.html">
     8.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_09/00_Inference.html">
   9. Inference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/01_Confidence_Intervals_Method.html">
     9.1. Confidence Intervals: Method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/02_Confidence_Intervals_Interpretation.html">
     9.2. Confidence Intervals: Interpretation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/03_Testing_Hypotheses.html">
     9.3. Testing Hypotheses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/04_AB_Testing_Fishers_Exact_Test.html">
     9.4. A/B Testing: Fisher’s Exact Test
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/05_Exercises.html">
     9.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_10/00_Probability_Density.html">
   10. Probability Density
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/01_Density.html">
     10.1. Density
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/02_Expectation_and_Variance.html">
     10.2. Expectation and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/03_The_Exponential_Distribution.html">
     10.3. Exponential Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/04_The_Normal_Distribution.html">
     10.4. The Normal Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/05_Exercises.html">
     10.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_11/00_Bias_Variance_and_Least_Squares.html">
   11. Bias, Variance, and Least Squares
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/01_Bias_and_Variance.html">
     11.1. Bias and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/02_German_Tank_Problem_Revisited.html">
     11.2. The German Tank Problem, Revisited
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/03_Least_Squares_Linear_Regression.html">
     11.3. Least Squares Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/04_Bounds_on_Correlation.html">
     11.4. Bounds on Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/05_The_Error_in_Regression.html">
     11.5. The Error in Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/06_Exercises.html">
     11.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="00_Inference_in_Regression.html">
   12. Inference in Regression
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="01_The_Simple_Linear_Regression_Model.html">
     12.1. The Simple Linear Regression Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_The_Distribution_of_the_Estimated_Slope.html">
     12.2. The Distribution of the Estimated Slope
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     12.3. Towards Multiple Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_Exercises.html">
     12.4. Exercises
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/content/Chapter_12/03_Towards_Multiple_Regression.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multiple-regression">
   12.3.1. Multiple Regression
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Towards Multiple Regression</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multiple-regression">
   12.3.1. Multiple Regression
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="cell tag_remove_input docutils container">
</div>
<section id="towards-multiple-regression">
<h1><span class="section-number">12.3. </span>Towards Multiple Regression<a class="headerlink" href="#towards-multiple-regression" title="Permalink to this headline">#</a></h1>
<p>This section is an extended example of applications of the methods we have derived for regression. We will start with simple regression, which we understand well, and will then indicate how some of the results can be extended when there is more than one predictor variable.</p>
<p>The data are from a study on the treatment of Hodgkin’s disease, a type of cancer that can affect young people. The good news is that treatments for this cancer have <a class="reference external" href="https://en.wikipedia.org/wiki/Hodgkin_lymphoma#Prognosis">high success rates</a>. The bad news is that the treatments can be rather strong combinations of chemotherapy and radiation, and thus have serious side effects. A goal of the study was to identify combinations of treatments with reduced side effects.</p>
<p>The table <code class="docutils literal notranslate"><span class="pre">hodgkins</span></code> contains data on a random sample of patients. Each row corresponds to a patient. The columns contain the patient’s height in centimeters, the amount of radiation, the amount of medication used in chemotherapy, and measurements on the health of the patient’s lungs.</p>
<div class="cell tag_remove_input docutils container">
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hodgkins</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table border="1" class="dataframe">
    <thead>
        <tr>
            <th>height</th> <th>rad</th> <th>chemo</th> <th>base</th> <th>month15</th> <th>difference</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>164   </td> <td>679 </td> <td>180  </td> <td>160.57</td> <td>87.77  </td> <td>-72.8     </td>
        </tr>
        <tr>
            <td>168   </td> <td>311 </td> <td>180  </td> <td>98.24 </td> <td>67.62  </td> <td>-30.62    </td>
        </tr>
        <tr>
            <td>173   </td> <td>388 </td> <td>239  </td> <td>129.04</td> <td>133.33 </td> <td>4.29      </td>
        </tr>
        <tr>
            <td>157   </td> <td>370 </td> <td>168  </td> <td>85.41 </td> <td>81.28  </td> <td>-4.13     </td>
        </tr>
        <tr>
            <td>160   </td> <td>468 </td> <td>151  </td> <td>67.94 </td> <td>79.26  </td> <td>11.32     </td>
        </tr>
        <tr>
            <td>170   </td> <td>341 </td> <td>96   </td> <td>150.51</td> <td>80.97  </td> <td>-69.54    </td>
        </tr>
        <tr>
            <td>163   </td> <td>453 </td> <td>134  </td> <td>129.88</td> <td>69.24  </td> <td>-60.64    </td>
        </tr>
        <tr>
            <td>175   </td> <td>529 </td> <td>264  </td> <td>87.45 </td> <td>56.48  </td> <td>-30.97    </td>
        </tr>
        <tr>
            <td>185   </td> <td>392 </td> <td>240  </td> <td>149.84</td> <td>106.99 </td> <td>-42.85    </td>
        </tr>
        <tr>
            <td>178   </td> <td>479 </td> <td>216  </td> <td>92.24 </td> <td>73.43  </td> <td>-18.81    </td>
        </tr>
    </tbody>
</table>
<p>... (12 rows omitted)</p></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="n">hodgkins</span><span class="o">.</span><span class="n">num_rows</span>
<span class="n">n</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>22
</pre></div>
</div>
</div>
</div>
<p>The radiation was directed towards each patient’s chest area or “mantle”, to destroy cancer cells in the lymph nodes near that area. Since this could adversely affect the patients’ lungs, the researchers measured the health of the patients’ lungs both before and after treatment. Each patient received a score, with larger scores corresponding to more healthy lungs.</p>
<p>The table records the baseline scores and also the scores 15 months after treatment. The change in score (15 month score minus baseline score) is in the final column. Notice the negative differences: 15 months after treatment, many patients’ lungs weren’t doing as well as before the treatment.</p>
<p>Perhaps not surprisingly, patients with larger baseline scores had bigger drops in score.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hodgkins</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">&#39;base&#39;</span><span class="p">,</span> <span class="s1">&#39;difference&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/03_Towards_Multiple_Regression_7_0.png" src="../../_images/03_Towards_Multiple_Regression_7_0.png" />
</div>
</div>
<p>We will regress the difference on the baseline score, this time using the Python module <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> that allows us to easily perform multiple regression as well. You don’t have to learn the code below (though it’s not hard). Just focus on understanding an interpreting the output.</p>
<p>As a first step, we must import the module.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">Table</span></code> method <code class="docutils literal notranslate"><span class="pre">to_df</span></code> allows us to convert the table <code class="docutils literal notranslate"><span class="pre">hodgkins</span></code> to a structure called a data frame that works more smoothly with <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h_data</span> <span class="o">=</span> <span class="n">hodgkins</span><span class="o">.</span><span class="n">to_df</span><span class="p">()</span>
<span class="n">h_data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>height</th>
      <th>rad</th>
      <th>chemo</th>
      <th>base</th>
      <th>month15</th>
      <th>difference</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>164</td>
      <td>679</td>
      <td>180</td>
      <td>160.57</td>
      <td>87.77</td>
      <td>-72.80</td>
    </tr>
    <tr>
      <th>1</th>
      <td>168</td>
      <td>311</td>
      <td>180</td>
      <td>98.24</td>
      <td>67.62</td>
      <td>-30.62</td>
    </tr>
    <tr>
      <th>2</th>
      <td>173</td>
      <td>388</td>
      <td>239</td>
      <td>129.04</td>
      <td>133.33</td>
      <td>4.29</td>
    </tr>
    <tr>
      <th>3</th>
      <td>157</td>
      <td>370</td>
      <td>168</td>
      <td>85.41</td>
      <td>81.28</td>
      <td>-4.13</td>
    </tr>
    <tr>
      <th>4</th>
      <td>160</td>
      <td>468</td>
      <td>151</td>
      <td>67.94</td>
      <td>79.26</td>
      <td>11.32</td>
    </tr>
    <tr>
      <th>5</th>
      <td>170</td>
      <td>341</td>
      <td>96</td>
      <td>150.51</td>
      <td>80.97</td>
      <td>-69.54</td>
    </tr>
    <tr>
      <th>6</th>
      <td>163</td>
      <td>453</td>
      <td>134</td>
      <td>129.88</td>
      <td>69.24</td>
      <td>-60.64</td>
    </tr>
    <tr>
      <th>7</th>
      <td>175</td>
      <td>529</td>
      <td>264</td>
      <td>87.45</td>
      <td>56.48</td>
      <td>-30.97</td>
    </tr>
    <tr>
      <th>8</th>
      <td>185</td>
      <td>392</td>
      <td>240</td>
      <td>149.84</td>
      <td>106.99</td>
      <td>-42.85</td>
    </tr>
    <tr>
      <th>9</th>
      <td>178</td>
      <td>479</td>
      <td>216</td>
      <td>92.24</td>
      <td>73.43</td>
      <td>-18.81</td>
    </tr>
    <tr>
      <th>10</th>
      <td>179</td>
      <td>376</td>
      <td>160</td>
      <td>117.43</td>
      <td>101.61</td>
      <td>-15.82</td>
    </tr>
    <tr>
      <th>11</th>
      <td>181</td>
      <td>539</td>
      <td>196</td>
      <td>129.75</td>
      <td>90.78</td>
      <td>-38.97</td>
    </tr>
    <tr>
      <th>12</th>
      <td>173</td>
      <td>217</td>
      <td>204</td>
      <td>97.59</td>
      <td>76.38</td>
      <td>-21.21</td>
    </tr>
    <tr>
      <th>13</th>
      <td>166</td>
      <td>456</td>
      <td>192</td>
      <td>81.29</td>
      <td>67.66</td>
      <td>-13.63</td>
    </tr>
    <tr>
      <th>14</th>
      <td>170</td>
      <td>252</td>
      <td>150</td>
      <td>98.29</td>
      <td>55.51</td>
      <td>-42.78</td>
    </tr>
    <tr>
      <th>15</th>
      <td>165</td>
      <td>622</td>
      <td>162</td>
      <td>118.98</td>
      <td>90.92</td>
      <td>-28.06</td>
    </tr>
    <tr>
      <th>16</th>
      <td>173</td>
      <td>305</td>
      <td>213</td>
      <td>103.17</td>
      <td>79.74</td>
      <td>-23.43</td>
    </tr>
    <tr>
      <th>17</th>
      <td>174</td>
      <td>566</td>
      <td>198</td>
      <td>94.97</td>
      <td>93.08</td>
      <td>-1.89</td>
    </tr>
    <tr>
      <th>18</th>
      <td>173</td>
      <td>322</td>
      <td>119</td>
      <td>85.00</td>
      <td>41.96</td>
      <td>-43.04</td>
    </tr>
    <tr>
      <th>19</th>
      <td>173</td>
      <td>270</td>
      <td>160</td>
      <td>115.02</td>
      <td>81.12</td>
      <td>-33.90</td>
    </tr>
    <tr>
      <th>20</th>
      <td>183</td>
      <td>259</td>
      <td>241</td>
      <td>125.02</td>
      <td>97.18</td>
      <td>-27.84</td>
    </tr>
    <tr>
      <th>21</th>
      <td>188</td>
      <td>238</td>
      <td>252</td>
      <td>137.43</td>
      <td>113.20</td>
      <td>-24.23</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>There are several variables we could use to predict the difference. The only one we wouldn’t use is the 15 month measurement, as that’s precisely what we won’t have for a new patient before the treatment is adminstered.</p>
<p>But which of the rest should we use? One way to choose is to look at the <em>correlation matrix</em> of all the variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h_data</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>height</th>
      <th>rad</th>
      <th>chemo</th>
      <th>base</th>
      <th>month15</th>
      <th>difference</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>height</th>
      <td>1.000000</td>
      <td>-0.305206</td>
      <td>0.576825</td>
      <td>0.354229</td>
      <td>0.390527</td>
      <td>-0.043394</td>
    </tr>
    <tr>
      <th>rad</th>
      <td>-0.305206</td>
      <td>1.000000</td>
      <td>-0.003739</td>
      <td>0.096432</td>
      <td>0.040616</td>
      <td>-0.073453</td>
    </tr>
    <tr>
      <th>chemo</th>
      <td>0.576825</td>
      <td>-0.003739</td>
      <td>1.000000</td>
      <td>0.062187</td>
      <td>0.445788</td>
      <td>0.346310</td>
    </tr>
    <tr>
      <th>base</th>
      <td>0.354229</td>
      <td>0.096432</td>
      <td>0.062187</td>
      <td>1.000000</td>
      <td>0.561371</td>
      <td>-0.630183</td>
    </tr>
    <tr>
      <th>month15</th>
      <td>0.390527</td>
      <td>0.040616</td>
      <td>0.445788</td>
      <td>0.561371</td>
      <td>1.000000</td>
      <td>0.288794</td>
    </tr>
    <tr>
      <th>difference</th>
      <td>-0.043394</td>
      <td>-0.073453</td>
      <td>0.346310</td>
      <td>-0.630183</td>
      <td>0.288794</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Each entry in this table is the correlation between the variable specified by the row label and the variable specified by the column label. That’s why all the diagonal entries are <span class="math notranslate nohighlight">\(1\)</span>.</p>
<p>Look at the last column (or last row). This contains the correlation between <code class="docutils literal notranslate"><span class="pre">difference</span></code> and each of the other variables. The baseline measurement has the largest correlation. To run the regression of <code class="docutils literal notranslate"><span class="pre">difference</span></code> on <code class="docutils literal notranslate"><span class="pre">base</span></code> we must first extract the columns of data that we need and then use the appropriate <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> methods.</p>
<p>First, we create data frames corresponding to the response and the predictor variable. The methods are not the same as for <code class="docutils literal notranslate"><span class="pre">Tables</span></code>, but you will get a general sense of what they are doing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">h_data</span><span class="p">[[</span><span class="s1">&#39;difference&#39;</span><span class="p">]]</span>  <span class="c1"># response</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">h_data</span><span class="p">[[</span><span class="s1">&#39;base&#39;</span><span class="p">]]</span>        <span class="c1"># predictor</span>

<span class="c1"># specify that the model includes an intercept</span>
<span class="n">x_with_int</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<p>The name of the <code class="docutils literal notranslate"><span class="pre">OLS</span></code> method stands for Ordinary Least Squares, which is the kind of least squares that we have discussed. There are other more complicated kinds that you might encounter in more advanced classes.</p>
<p>There is a lot of output, some of which we will discuss and the rest of which we will leave to another class. For some reason the output includes the date and time of running the regression, right in the middle of the summary statistics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simple_regression</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x_with_int</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">simple_regression</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>       <td>difference</td>    <th>  R-squared:         </th> <td>   0.397</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.367</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   13.17</td>
</tr>
<tr>
  <th>Date:</th>             <td>Fri, 21 Oct 2022</td> <th>  Prob (F-statistic):</th>  <td>0.00167</td>
</tr>
<tr>
  <th>Time:</th>                 <td>13:34:28</td>     <th>  Log-Likelihood:    </th> <td> -92.947</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    22</td>      <th>  AIC:               </th> <td>   189.9</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    20</td>      <th>  BIC:               </th> <td>   192.1</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th> <td>   32.1721</td> <td>   17.151</td> <td>    1.876</td> <td> 0.075</td> <td>   -3.604</td> <td>   67.949</td>
</tr>
<tr>
  <th>base</th>  <td>   -0.5447</td> <td>    0.150</td> <td>   -3.630</td> <td> 0.002</td> <td>   -0.858</td> <td>   -0.232</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 1.133</td> <th>  Durbin-Watson:     </th> <td>   1.774</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.568</td> <th>  Jarque-Bera (JB):  </th> <td>   0.484</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.362</td> <th>  Prob(JB):          </th> <td>   0.785</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.069</td> <th>  Cond. No.          </th> <td>    530.</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>There are three blocks of output. We will focus only on the the middle block.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">const</span></code> and <code class="docutils literal notranslate"><span class="pre">base</span></code> refer to the intercept and baseline measurement.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">coef</span></code> stands for the estimated coefficients, which in our notation are <span class="math notranslate nohighlight">\(\hat{\beta_0}\)</span> and <span class="math notranslate nohighlight">\(\hat{\beta_1}\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">t</span></code> is the <span class="math notranslate nohighlight">\(t\)</span>-statistic for testing whether or not the coefficient is 0. Based on our model, its degrees of freedom are <span class="math notranslate nohighlight">\(n-2 = 20\)</span>; you’ll find this under <code class="docutils literal notranslate"><span class="pre">Df</span> <span class="pre">Residuals</span></code> in the top block.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">P</span> <span class="pre">&gt;</span> <span class="pre">|t|</span></code> is the total area in the two tails of the <span class="math notranslate nohighlight">\(t\)</span> distribution with <span class="math notranslate nohighlight">\(n-2\)</span> degrees of freedom.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[0.025</span> <span class="pre">0.975]</span></code> are the ends of a 95% confidence interval for the parameter.</p></li>
</ul>
<p>For the test of whether or not the true slope of the baseline measurement is <span class="math notranslate nohighlight">\(0\)</span>, the observed test statistic is</p>
<div class="math notranslate nohighlight">
\[
\frac{-0.5447 - 0}{0.150} ~ = ~ -3.63
\]</div>
<p>The area in one tail is the chance that the <span class="math notranslate nohighlight">\(t\)</span> distribution with <span class="math notranslate nohighlight">\(20\)</span> degrees of freedom is less than <span class="math notranslate nohighlight">\(-3.63\)</span>. That’s the cdf of the distribution evaluated at <span class="math notranslate nohighlight">\(-3.63\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">one_tail</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="o">-</span><span class="mf">3.63</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">one_tail</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0008339581409629714
</pre></div>
</div>
</div>
</div>
<p>Our test is two-sided (large values of <span class="math notranslate nohighlight">\(\vert t \vert\)</span> favor the alternative), so the <span class="math notranslate nohighlight">\(p\)</span>-value of the test is the total area of two tails, which is the displayed value <span class="math notranslate nohighlight">\(0.002\)</span> after rounding.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">one_tail</span>
<span class="n">p</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0016679162819259429
</pre></div>
</div>
</div>
</div>
<p>To find a 95% confidence interval for the true slope, we have to replace <span class="math notranslate nohighlight">\(2\)</span> in the expression <span class="math notranslate nohighlight">\(\hat{\beta}_1 \pm 2SE(\hat{\beta}_1)\)</span> by the corresponding value from the <span class="math notranslate nohighlight">\(t\)</span> distribution with 20 degrees of freedom. That’s not very far from <span class="math notranslate nohighlight">\(2\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t_95</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.975</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">t_95</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.0859634472658364
</pre></div>
</div>
</div>
</div>
<p>A 95% confidence interval for the true slope is given by <span class="math notranslate nohighlight">\(\hat{\beta}_1 \pm t_{95}SE(\hat{\beta}_1)\)</span>. The observed interval is therefore given by the calculation below, which results in the same values as in the output of <code class="docutils literal notranslate"><span class="pre">sm.OLS</span></code> above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 95% confidence interval for the true slope</span>

<span class="o">-</span><span class="mf">0.5447</span> <span class="o">-</span> <span class="n">t_95</span><span class="o">*</span><span class="mf">0.150</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5447</span> <span class="o">+</span> <span class="n">t_95</span><span class="o">*</span><span class="mf">0.150</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(-0.8575945170898753, -0.23180548291012454)
</pre></div>
</div>
</div>
</div>
<section id="multiple-regression">
<h2><span class="section-number">12.3.1. </span>Multiple Regression<a class="headerlink" href="#multiple-regression" title="Permalink to this headline">#</a></h2>
<p>What if we wanted to regress <code class="docutils literal notranslate"><span class="pre">difference</span></code> on both <code class="docutils literal notranslate"><span class="pre">base</span></code> and <code class="docutils literal notranslate"><span class="pre">chemo</span></code>? The first thing to do would be to check the correlation matrix again:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h_data</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>height</th>
      <th>rad</th>
      <th>chemo</th>
      <th>base</th>
      <th>month15</th>
      <th>difference</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>height</th>
      <td>1.000000</td>
      <td>-0.305206</td>
      <td>0.576825</td>
      <td>0.354229</td>
      <td>0.390527</td>
      <td>-0.043394</td>
    </tr>
    <tr>
      <th>rad</th>
      <td>-0.305206</td>
      <td>1.000000</td>
      <td>-0.003739</td>
      <td>0.096432</td>
      <td>0.040616</td>
      <td>-0.073453</td>
    </tr>
    <tr>
      <th>chemo</th>
      <td>0.576825</td>
      <td>-0.003739</td>
      <td>1.000000</td>
      <td>0.062187</td>
      <td>0.445788</td>
      <td>0.346310</td>
    </tr>
    <tr>
      <th>base</th>
      <td>0.354229</td>
      <td>0.096432</td>
      <td>0.062187</td>
      <td>1.000000</td>
      <td>0.561371</td>
      <td>-0.630183</td>
    </tr>
    <tr>
      <th>month15</th>
      <td>0.390527</td>
      <td>0.040616</td>
      <td>0.445788</td>
      <td>0.561371</td>
      <td>1.000000</td>
      <td>0.288794</td>
    </tr>
    <tr>
      <th>difference</th>
      <td>-0.043394</td>
      <td>-0.073453</td>
      <td>0.346310</td>
      <td>-0.630183</td>
      <td>0.288794</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>What you are looking for is not just that <code class="docutils literal notranslate"><span class="pre">chemo</span></code> is the next most highly correlated with <code class="docutils literal notranslate"><span class="pre">difference</span></code> after <code class="docutils literal notranslate"><span class="pre">base</span></code>. More importantly, you are looking to see how strongly the two predictor variables <code class="docutils literal notranslate"><span class="pre">base</span></code> and <code class="docutils literal notranslate"><span class="pre">chemo</span></code> are linearly related <em>to each other</em>. That is, you are trying to figure out whether the two variables pick up genuinely different dimensions of the data.</p>
<p>The correlation matrix shows that the correlation between <code class="docutils literal notranslate"><span class="pre">base</span></code> and <code class="docutils literal notranslate"><span class="pre">chemo</span></code> is only about <span class="math notranslate nohighlight">\(0.06\)</span>. The two predictors are not close to being linear functions of each other. So let’s run the regression.</p>
<p>The code is exactly the same as before, except that we have included a second predictor variable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">h_data</span><span class="p">[[</span><span class="s1">&#39;difference&#39;</span><span class="p">]]</span>      <span class="c1"># response</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">h_data</span><span class="p">[[</span><span class="s1">&#39;base&#39;</span><span class="p">,</span> <span class="s1">&#39;chemo&#39;</span><span class="p">]]</span>  <span class="c1"># predictors</span>

<span class="c1"># specify that the model includes an intercept</span>
<span class="n">x2_with_int</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span> 

<span class="n">multiple_regression</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x2_with_int</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">multiple_regression</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>       <td>difference</td>    <th>  R-squared:         </th> <td>   0.546</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.499</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.44</td>
</tr>
<tr>
  <th>Date:</th>             <td>Fri, 21 Oct 2022</td> <th>  Prob (F-statistic):</th> <td>0.000548</td>
</tr>
<tr>
  <th>Time:</th>                 <td>13:34:28</td>     <th>  Log-Likelihood:    </th> <td> -89.820</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    22</td>      <th>  AIC:               </th> <td>   185.6</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    19</td>      <th>  BIC:               </th> <td>   188.9</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th> <td>   -0.9992</td> <td>   20.227</td> <td>   -0.049</td> <td> 0.961</td> <td>  -43.335</td> <td>   41.336</td>
</tr>
<tr>
  <th>base</th>  <td>   -0.5655</td> <td>    0.134</td> <td>   -4.226</td> <td> 0.000</td> <td>   -0.846</td> <td>   -0.285</td>
</tr>
<tr>
  <th>chemo</th> <td>    0.1898</td> <td>    0.076</td> <td>    2.500</td> <td> 0.022</td> <td>    0.031</td> <td>    0.349</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 0.853</td> <th>  Durbin-Watson:     </th> <td>   1.781</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.653</td> <th>  Jarque-Bera (JB):  </th> <td>   0.368</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.317</td> <th>  Prob(JB):          </th> <td>   0.832</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.987</td> <th>  Cond. No.          </th> <td>1.36e+03</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.36e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.</div></div>
</div>
<p>Ignore the scary warning above. There isn’t strong multicollinearity (predictor variables being highly correlated with each other) nor other serious issues.</p>
<p>Just focus on the middle block of the output. It’s just like the middle block of the simple regression output, with one more line corresponding to <code class="docutils literal notranslate"><span class="pre">chemo</span></code>.</p>
<p>All of the values in the block are interpreted in the same way as before. The only change is in the degrees of freedom: because you are estimating one more parameter, the degrees of freedom have dropped by <span class="math notranslate nohighlight">\(1\)</span>, and are thus <span class="math notranslate nohighlight">\(19\)</span> instead of <span class="math notranslate nohighlight">\(20\)</span>.</p>
<p>For example, the 95% confidence interval for the slope of <code class="docutils literal notranslate"><span class="pre">chemo</span></code> is calculated as follows.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t_95_df19</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.975</span><span class="p">,</span> <span class="mi">19</span><span class="p">)</span>

<span class="mf">0.1898</span> <span class="o">-</span> <span class="n">t_95_df19</span><span class="o">*</span><span class="mf">0.076</span><span class="p">,</span> <span class="mf">0.1898</span> <span class="o">+</span> <span class="n">t_95_df19</span><span class="o">*</span><span class="mf">0.076</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.03073017186497201, 0.348869828135028)
</pre></div>
</div>
</div>
</div>
<p>Finally, take a look at the value of <code class="docutils literal notranslate"><span class="pre">R-squared</span></code> in the very top line. It is <span class="math notranslate nohighlight">\(0.546\)</span> compared to <span class="math notranslate nohighlight">\(0.397\)</span> for the simple regression. It’s a math fact that the more predictor variables you use, the higher the <code class="docutils literal notranslate"><span class="pre">R-squared</span></code> value will be. This tempts people into using lots of predictors, whether or not the resulting model is comprehensible.</p>
<p>With an “everything as well as the kitchen sink” approach to selecting predictor variables, a researcher might be inclined to use all the possible predictors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">h_data</span><span class="p">[[</span><span class="s1">&#39;difference&#39;</span><span class="p">]]</span>      <span class="c1"># response</span>
<span class="n">x3</span> <span class="o">=</span> <span class="n">h_data</span><span class="p">[[</span><span class="s1">&#39;base&#39;</span><span class="p">,</span> <span class="s1">&#39;chemo&#39;</span><span class="p">,</span> <span class="s1">&#39;rad&#39;</span><span class="p">,</span> <span class="s1">&#39;height&#39;</span><span class="p">]]</span>  <span class="c1"># predictors</span>

<span class="c1"># specify that the model includes an intercept</span>
<span class="n">x3_with_int</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">x3</span><span class="p">)</span> 

<span class="n">bad_regression</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x3_with_int</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">bad_regression</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>       <td>difference</td>    <th>  R-squared:         </th> <td>   0.550</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.444</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.185</td>
</tr>
<tr>
  <th>Date:</th>             <td>Fri, 21 Oct 2022</td> <th>  Prob (F-statistic):</th>  <td>0.00645</td>
</tr>
<tr>
  <th>Time:</th>                 <td>13:34:29</td>     <th>  Log-Likelihood:    </th> <td> -89.741</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    22</td>      <th>  AIC:               </th> <td>   189.5</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    17</td>      <th>  BIC:               </th> <td>   194.9</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th>  <td>   33.5226</td> <td>  101.061</td> <td>    0.332</td> <td> 0.744</td> <td> -179.698</td> <td>  246.743</td>
</tr>
<tr>
  <th>base</th>   <td>   -0.5393</td> <td>    0.160</td> <td>   -3.378</td> <td> 0.004</td> <td>   -0.876</td> <td>   -0.202</td>
</tr>
<tr>
  <th>chemo</th>  <td>    0.2124</td> <td>    0.103</td> <td>    2.053</td> <td> 0.056</td> <td>   -0.006</td> <td>    0.431</td>
</tr>
<tr>
  <th>rad</th>    <td>   -0.0062</td> <td>    0.031</td> <td>   -0.203</td> <td> 0.841</td> <td>   -0.071</td> <td>    0.059</td>
</tr>
<tr>
  <th>height</th> <td>   -0.2274</td> <td>    0.658</td> <td>   -0.346</td> <td> 0.734</td> <td>   -1.615</td> <td>    1.160</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 0.589</td> <th>  Durbin-Watson:     </th> <td>   1.812</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.745</td> <th>  Jarque-Bera (JB):  </th> <td>   0.321</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.286</td> <th>  Prob(JB):          </th> <td>   0.852</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.851</td> <th>  Cond. No.          </th> <td>1.46e+04</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.46e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems.</div></div>
</div>
<p>This is not a good idea. We end up with a far more complicated model for no appreciable gain in <code class="docutils literal notranslate"><span class="pre">R-squared</span></code>. The “adjusted <span class="math notranslate nohighlight">\(R^2\)</span>” penalizes us for using more predictor variables: notice that the value of <code class="docutils literal notranslate"><span class="pre">Adj.</span> <span class="pre">R-squared</span></code> is smaller for the regression with all the predictors than for the regression with just <code class="docutils literal notranslate"><span class="pre">base</span></code> and <code class="docutils literal notranslate"><span class="pre">chemo</span></code>.</p>
<p>Curious about how to select predictors, or about what makes a good regression? Then take some more statistics classes! This one is complete.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content\Chapter_12"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="02_The_Distribution_of_the_Estimated_Slope.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">12.2. </span>The Distribution of the Estimated Slope</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="04_Exercises.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">12.4. </span>Exercises</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ani Adhikari<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>