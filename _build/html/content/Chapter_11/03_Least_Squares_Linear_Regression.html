
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>11.3. Least Squares Linear Regression &#8212; Data 88S Textbook</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="11.4. Bounds on Correlation" href="04_Bounds_on_Correlation.html" />
    <link rel="prev" title="11.2. Examples" href="02_Examples.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/data88s_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data 88S Textbook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="http://stat88.org">
   Course Home
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapters
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_01/00_The_Basics.html">
   1. The Basics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/01_Probabilities_as_Proportions.html">
     1.1. Probabilities as Proportions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/02_Exact_Calculation_or_Bound.html">
     1.2. Exact Calculation, or Bound?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/03_Fundamental_Rules.html">
     1.3. Fundamental Rules
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/04_Exercises.html">
     1.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_02/00_Intersections_and_Conditioning.html">
   2. Intersections and Conditioning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/01_The_Chance_of_an_Intersection.html">
     2.1. The Chance of an Intersection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/02_Symmetry_in_Simple_Random_Sampling.html">
     2.2. Symmetry in Simple Random Sampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/03_Bayes_Rule.html">
     2.3. Bayes’ Rule
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/04_Use_and_Interpretation.html">
     2.4. Use and Interpretation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/05_Independence.html">
     2.5. Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/06_Exercises.html">
     2.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_03/00_Random_Counts.html">
   3. Random Counts
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/01_Success_and_Failure.html">
     3.1. Success and Failure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/02_Random_Variables.html">
     3.2. Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/03_The_Binomial_Distribution.html">
     3.3. The Binomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/04_The_Hypergeometric_Distribution.html">
     3.4. The Hypergeometric Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/05_Examples.html">
     3.5. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/06_Exercises.html">
     3.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_04/00_Infinitely_Many_Values.html">
   4. Infinitely Many Values
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/01_Cumulative_Distribution_Function.html">
     4.1. Cumulative Distribution Function (CDF)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/02_Waiting_Times.html">
     4.2. Waiting Times
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/03_Exponential_Approximations.html">
     4.3. Exponential Approximations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/04_The_Poisson_Distribution.html">
     4.4. The Poisson Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/05_Exercises.html">
     4.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_05/00_Expectation.html">
   5. Expectation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/01_Definition.html">
     5.1. Definition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/02_Functions_of_Random_Variables.html">
     5.2. Functions of Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/03_Method_of_Indicators.html">
     5.3. Method of Indicators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/04_Unbiased_Estimators.html">
     5.4. Unbiased Estimators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/05_Conditional_Expectation.html">
     5.5. Conditional Expectation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/06_Expectation_by_Conditioning.html">
     5.6. Expectation by Conditioning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/07_Exercises.html">
     5.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_06/00_Measuring_Variability.html">
   6. Measuring Variability
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/01_Variance_and_Standard_Deviation.html">
     6.1. Variance and Standard Deviation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/02_Simplifying_the_Calculation.html">
     6.2. Simplifying the Calculation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/03_Markovs_Inequality.html">
     6.3. Markov’s Inequality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/04_Chebyshevs_Inequality.html">
     6.4. Chebyshev’s Inequality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/05_Exercises.html">
     6.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_07/00_The_Variance_of_a_Sum.html">
   7. The Variance of a Sum
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/01_Sums_of_Independent_Random_Variables.html">
     7.1. Sums of Independent Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/02_Sampling_Without_Replacement.html">
     7.2. Sampling Without Replacement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/03_The_Law_of_Averages.html">
     7.3. The Law of Averages
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/04_Exercises.html">
     7.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_08/00_Central_Limit_Theorem.html">
   8. Central Limit Theorem
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/01_Distribution_of_a_Sample_Sum.html">
     8.1. The Distribution of a Sample Sum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/02_Standard_Normal_Curve.html">
     8.2. Standard Normal Curve
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/03_Normal_Approximation.html">
     8.3. Normal Approximation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/04_How_Large_is_Large.html">
     8.4. How Large is “Large”?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/05_Exercises.html">
     8.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_09/00_Inference.html">
   9. Inference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/01_Confidence_Intervals_Method.html">
     9.1. Confidence Intervals: Method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/02_Confidence_Intervals_Interpretation.html">
     9.2. Confidence Intervals: Interpretation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/03_Testing_Hypotheses.html">
     9.3. Testing Hypotheses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/04_AB_Testing_Fishers_Exact_Test.html">
     9.4. A/B Testing: Fisher’s Exact Test
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/05_Exercises.html">
     9.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_10/00_Probability_Density.html">
   10. Probability Density
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/01_Density.html">
     10.1. Density
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/02_Expectation_and_Variance.html">
     10.2. Expectation and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/03_The_Exponential_Distribution.html">
     10.3. Exponential Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/04_The_Normal_Distribution.html">
     10.4. The Normal Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/05_Exercises.html">
     10.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="00_Bias_Variance_and_Least_Squares.html">
   11. Bias, Variance, and Least Squares
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="01_Bias_and_Variance.html">
     11.1. Bias and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_Examples.html">
     11.2. Examples
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     11.3. Least Squares Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_Bounds_on_Correlation.html">
     11.4. Bounds on Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05_The_Error_in_Regression.html">
     11.5. The Error in Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06_Exercises.html">
     11.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_12/00_Inference_in_Regression.html">
   12. Inference in Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/01_The_Simple_Linear_Regression_Model.html">
     12.1. The Simple Linear Regression Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/02_The_Distribution_of_the_Estimated_Slope.html">
     12.2. The Distribution of the Estimated Slope
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/03_Towards_Multiple_Regression.html">
     12.3. Towards Multiple Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/04_Exercises.html">
     12.4. Exercises
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/content/Chapter_11/03_Least_Squares_Linear_Regression.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mean-squared-error">
   11.3.1. Mean Squared Error
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#best-intercept-for-a-fixed-slope">
   11.3.2. Best Intercept for a Fixed Slope
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#best-slope">
   11.3.3. Best Slope
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#correlation">
   11.3.4. Correlation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-familiar-formula-for-the-best-slope">
   11.3.5. A Familiar Formula for the Best Slope
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#equation-of-the-regression-line">
   11.3.6. Equation of the Regression Line
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Least Squares Linear Regression</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mean-squared-error">
   11.3.1. Mean Squared Error
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#best-intercept-for-a-fixed-slope">
   11.3.2. Best Intercept for a Fixed Slope
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#best-slope">
   11.3.3. Best Slope
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#correlation">
   11.3.4. Correlation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-familiar-formula-for-the-best-slope">
   11.3.5. A Familiar Formula for the Best Slope
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#equation-of-the-regression-line">
   11.3.6. Equation of the Regression Line
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="least-squares-linear-regression">
<h1><span class="section-number">11.3. </span>Least Squares Linear Regression<a class="headerlink" href="#least-squares-linear-regression" title="Permalink to this headline">#</a></h1>
<p>The mean squared error is a criterion by which you can compare two estimators – the one with the smaller mean squared error is on average closer to the quantity you are trying to estimate. An important use of this criterion is to identify the best among a class of estimators.</p>
<p>For example, suppose you have a random pair <span class="math notranslate nohighlight">\((X, Y)\)</span> and you want to use a linear function of <span class="math notranslate nohighlight">\(X\)</span> to estimate <span class="math notranslate nohighlight">\(Y\)</span>. That is, you want to estimate <span class="math notranslate nohighlight">\(Y\)</span> by the function <span class="math notranslate nohighlight">\(aX + b\)</span> for some slope <span class="math notranslate nohighlight">\(a\)</span> and intercept <span class="math notranslate nohighlight">\(b\)</span>. Your goal is to find the best in the class of all linear functions. If the criterion is mean squared error, the goal is to see if there is a slope and an intercept that minimize the mean squared error.</p>
<p>This is the <a class="reference external" href="https://www.inferentialthinking.com/chapters/15/2/Regression_Line.html">regression</a> problem from Data 8, expressed in random variable notation. Recall that in Data 8 you were given formulas for the <a class="reference external" href="https://www.inferentialthinking.com/chapters/15/2/Regression_Line.html#The-Equation-of-the-Regression-Line">slope and intercept</a> of the “best” or “least squares” line, also known as the regression line. In Data 8 notation the formulas are:</p>
<div class="math notranslate nohighlight">
\[
\text{slope of the regression line} ~ = ~ r \frac{\text{SD of }y}{\text{SD of }x}
\]</div>
<p>where <span class="math notranslate nohighlight">\(r\)</span> is the correlation between the two variables (which we have not yet defined in this course), and</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp;\text{intercept of the regression line} \\
&amp;= ~ \text{(average of }y\text{)} - \text{slope}\times\text{(average of }x\text{)}
\end{align*}
\end{split}\]</div>
<p>Data 8 gives you two ways of confirming that the formulas work:</p>
<ul class="simple">
<li><p>By the <a class="reference external" href="https://www.inferentialthinking.com/chapters/15/2/Regression_Line.html#Identifying-the-Line-in-Standard-Units">geometry</a> of elliptical or “football shaped” scatter diagrams</p></li>
<li><p>By <a class="reference external" href="https://www.inferentialthinking.com/chapters/15/3/Method_of_Least_Squares.html#Minimizing-the-Root-Mean-Squared-Error">numerical minimization</a> of the mean squared error over all possible lines</p></li>
</ul>
<p>We will now derive the formulas mathematically using calculus and properties of expectation and variance.</p>
<p>First, some notation:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(E(X) = \mu_X\)</span>, <span class="math notranslate nohighlight">\(SD(X) = \sigma_X\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(E(Y) = \mu_Y\)</span>, <span class="math notranslate nohighlight">\(SD(Y) = \sigma_Y\)</span></p></li>
</ul>
<p>Also, some terminology: statistics that we have been calling “estimators” can also be called “predictors” depending on the context. Data 8 calls the regression estimate a regression prediction, and we will do that too.</p>
<section id="mean-squared-error">
<h2><span class="section-number">11.3.1. </span>Mean Squared Error<a class="headerlink" href="#mean-squared-error" title="Permalink to this headline">#</a></h2>
<p>For the random point <span class="math notranslate nohighlight">\((X, Y)\)</span>, the mean squared error of a linear predictor of <span class="math notranslate nohighlight">\(Y\)</span> based on <span class="math notranslate nohighlight">\(X\)</span> depends on the slope <span class="math notranslate nohighlight">\(a\)</span> and intercept <span class="math notranslate nohighlight">\(b\)</span> of the line used. So let us define <span class="math notranslate nohighlight">\(MSE(a, b)\)</span> to be the mean squared error when we use the line <span class="math notranslate nohighlight">\(aX + b\)</span> to predict <span class="math notranslate nohighlight">\(Y\)</span>. That is,</p>
<div class="math notranslate nohighlight">
\[
MSE(a, b) ~ = ~ E\left( (Y - (aX+b))^2 \right)
\]</div>
<p>We have to find the values of <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> that minimize this function. We will do that by calculus, in two stages.</p>
</section>
<section id="best-intercept-for-a-fixed-slope">
<h2><span class="section-number">11.3.2. </span>Best Intercept for a Fixed Slope<a class="headerlink" href="#best-intercept-for-a-fixed-slope" title="Permalink to this headline">#</a></h2>
<p>First, we will fix the slope and find the best intercept for that slope. The error can be rewritten as follows:</p>
<div class="math notranslate nohighlight">
\[
Y - (aX+b) ~ = ~ (Y-aX) - b
\]</div>
<p>For a fixed <span class="math notranslate nohighlight">\(a\)</span>, let <span class="math notranslate nohighlight">\(MSE_a(b) = MSE(a, b)\)</span> be considered as a function of <span class="math notranslate nohighlight">\(b\)</span> alone. Then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
MSE_a(b) ~ &amp;= ~ E\left( ((Y-aX) - b)^2 \right) \\
&amp;= ~ E\left( (Y-aX)^2 - 2b(Y-aX) + b^2 \right) \\
&amp;= ~ E\left( (Y-aX)^2\right) -2bE(Y-aX) + b^2
\end{align*}
\end{split}\]</div>
<p>Now</p>
<div class="math notranslate nohighlight">
\[
\frac{d}{db}MSE_a(b) ~ = ~ -2E(Y-aX) + 2b
\]</div>
<p>Set this equal to <span class="math notranslate nohighlight">\(0\)</span> and solve to see that the best intercept <span class="math notranslate nohighlight">\(\hat{b}_a\)</span> for the fixed slope <span class="math notranslate nohighlight">\(a\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
\hat{b}_a ~ = ~ E(Y-aX) ~ = ~ \mu_Y - a\mu_X
\]</div>
<p>This is consistent with the formula for the intercept of the regression line in Data 8:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
&amp;\text{intercept of the regression line} \\
&amp;= ~ \text{(average of }y\text{)} - \text{slope}\times\text{(average of }x\text{)}
\end{align*}
\end{split}\]</div>
<p>To be very thorough, we should take the second derivative, look at its sign, and confirm that we have a minimum rather than a maximum value of the mean squared error. But we will spare ourselves that calculation. We have enough experience from Data 8 to know that this is a minimum, not a maximum.</p>
</section>
<section id="best-slope">
<h2><span class="section-number">11.3.3. </span>Best Slope<a class="headerlink" href="#best-slope" title="Permalink to this headline">#</a></h2>
<p>We now have to find the best among all slopes. For each fixed slope <span class="math notranslate nohighlight">\(a\)</span> we must first plug in the best intercept we just found. Then the error in the prediction can be written as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
Y - (aX+\hat{b}_a) ~ &amp;= Y - (aX + \mu_Y - a\mu_X) \\
&amp;= ~ (Y-\mu_Y) - a(X-\mu_X) \\
&amp;= D_Y - aD_X
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(D_X\)</span> and <span class="math notranslate nohighlight">\(D_Y\)</span> are the deviations of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> from their respective means.</p>
<p>We have to minimize</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
MSE(a) ~ &amp;= ~ E\left( (D_Y - aD_X)^2 \right) \\
&amp;= ~ E(D_Y^2) -2aE(D_XD_Y) + a^2E(D_X^2) \\
&amp;= ~ \sigma_Y^2 -2aE(D_XD_Y) + a^2\sigma_X^2
\end{align*}
\end{split}\]</div>
<p>by the definition of variance. Now</p>
<div class="math notranslate nohighlight">
\[
\frac{d}{da}MSE(a) ~ = ~ -2E(D_XD_Y) + 2a\sigma_X^2
\]</div>
<p>Set this equal to <span class="math notranslate nohighlight">\(0\)</span> and solve to see that the best slope is</p>
<div class="math notranslate nohighlight">
\[
\hat{a} ~ = ~ \frac{E(D_XD_Y)}{\sigma_X^2} ~ = ~ \frac{E\big{(}(X-\mu_X)(Y-\mu_Y)\big{)}}{\sigma_X^2}
\]</div>
<p>This doesn’t look like the Data 8 formula for the slope of the regression line, but it is the way the slope of the regression line is often written. Let’s see if we can make it resemble the Data 8 formula.</p>
</section>
<section id="correlation">
<h2><span class="section-number">11.3.4. </span>Correlation<a class="headerlink" href="#correlation" title="Permalink to this headline">#</a></h2>
<p>The expected product <span class="math notranslate nohighlight">\(E(D_XD_Y)\)</span> is called the <em>covariance</em> of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>. Covariance is difficult to interpret because it has strange units. For example, if we were using educational level to predict income, then the covariance could be measured in units of years<span class="math notranslate nohighlight">\(\times\)</span>dollars, which is hard to understand.</p>
<p>One way to deal with this problem is to first divide each deviation by the corresponding SD, to get a pure number. This converts each variable to standard units. The expected product of standard units is called the <em>correlation coefficient</em> of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, or just correlation for short. We will denote it by <span class="math notranslate nohighlight">\(r(X, Y)\)</span> or just <span class="math notranslate nohighlight">\(r\)</span>.</p>
<div class="math notranslate nohighlight">
\[
r ~ = ~ r(X, Y) ~ = ~ E\Bigg( \left(\frac{X - \mu_X}{\sigma_X}\right)\left(\frac{Y - \mu_Y}{\sigma_Y}\right)\Bigg)
\]</div>
<p>This agrees with the <a class="reference external" href="https://www.inferentialthinking.com/chapters/15/1/Correlation.html#Calculating-%24r%24">Data 8 definition</a> of correlation, which says, “<span class="math notranslate nohighlight">\(r\)</span> is the average of the products of the two variables, when both variables are measured in standard units.”</p>
<p>We now have</p>
<div class="math notranslate nohighlight">
\[
E(D_XD_Y) ~ = ~ E\big{(}(X-\mu_X)(Y-\mu_Y)\big{)} ~ = ~ r\sigma_X\sigma_Y
\]</div>
</section>
<section id="a-familiar-formula-for-the-best-slope">
<h2><span class="section-number">11.3.5. </span>A Familiar Formula for the Best Slope<a class="headerlink" href="#a-familiar-formula-for-the-best-slope" title="Permalink to this headline">#</a></h2>
<p>The best slope can be written as</p>
<div class="math notranslate nohighlight">
\[
\hat{a} ~ = ~ \frac{E(D_XD_Y)}{\sigma_X^2} ~ = ~ \frac{r\sigma_X\sigma_Y}{\sigma_X^2} ~ = ~ r\frac{\sigma_Y}{\sigma_X}
\]</div>
<p>which is the same as the Data 8 formula for the slope of the regression line.</p>
</section>
<section id="equation-of-the-regression-line">
<h2><span class="section-number">11.3.6. </span>Equation of the Regression Line<a class="headerlink" href="#equation-of-the-regression-line" title="Permalink to this headline">#</a></h2>
<p>We have shown that no matter what the joint distribution of the pair <span class="math notranslate nohighlight">\((X, Y)\)</span>, there is a unique straight line that minimizes the mean squared error of prediction among all straight lines. This line is called the <em>regression line</em>, for reasons that you know from Data 8.</p>
<p>The equation of the regression line is</p>
<div class="math notranslate nohighlight">
\[
\hat{Y} ~ = ~ \hat{a}X + \hat{b}
\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{Y}\)</span> is the regression prediction of <span class="math notranslate nohighlight">\(Y\)</span> based on <span class="math notranslate nohighlight">\(X\)</span>, also known as the <em>fitted value</em> of <span class="math notranslate nohighlight">\(Y\)</span></p></li>
<li><p>the slope of the regression line is <span class="math notranslate nohighlight">\(\hat{a} = r\frac{\sigma_Y}{\sigma_X}\)</span></p></li>
<li><p>the intercept of the regression line is <span class="math notranslate nohighlight">\(\hat{b} = \mu_Y - \hat{a}\mu_X\)</span></p></li>
</ul>
<p>Sometimes it is useful to write the regression equation in a different form:</p>
<div class="math notranslate nohighlight">
\[
\hat{Y} ~ = ~ \hat{a}X + \mu_Y - \hat{a}\mu_X
~ = ~ \hat{a}(X - \mu_X) + \mu_Y
\]</div>
<p>This form can reduce calculation because <span class="math notranslate nohighlight">\(E(X - \mu_X) = 0\)</span> and <span class="math notranslate nohighlight">\(Var(X - \mu_X) = Var(X) = \sigma_X^2\)</span>. We will use it in later sections to study the error in the regression prediction.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content\Chapter_11"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="02_Examples.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">11.2. </span>Examples</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="04_Bounds_on_Correlation.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">11.4. </span>Bounds on Correlation</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ani Adhikari<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>