{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# NO CODE\n",
    "\n",
    "from datascience import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Towards Multiple Regression ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is an extended example of applications of the methods we have derived for regression. We will start with simple regression, which we understand well, and will then indicate how some of the results can be extended when there is more than one predictor variable.\n",
    "\n",
    "The data are from a study on the treatment of Hodgkin's disease, a type of cancer that can affect young people. The good news is that treatments for this cancer have [high success rates](https://en.wikipedia.org/wiki/Hodgkin_lymphoma#Prognosis). The bad news is that the treatments can be rather strong combinations of chemotherapy and radiation, and thus have serious side effects. A goal of the study was to identify combinations of treatments with reduced side effects.\n",
    "\n",
    "The table `hodgkins` contains data on a random sample of patients. Each row corresponds to a patient. The columns contain the patient's height in centimeters, the amount of radiation, the amount of medication used in chemotherapy, and measurements on the health of the patient's lungs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# NO CODE\n",
    "\n",
    "hodgkins = Table.read_table('../../data/hodgkins.csv')\n",
    "diffs = hodgkins.column(4) - hodgkins.column(3)\n",
    "hodgkins = hodgkins.with_columns('difference', diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>height</th> <th>rad</th> <th>chemo</th> <th>base</th> <th>month15</th> <th>difference</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>164   </td> <td>679 </td> <td>180  </td> <td>160.57</td> <td>87.77  </td> <td>-72.8     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>168   </td> <td>311 </td> <td>180  </td> <td>98.24 </td> <td>67.62  </td> <td>-30.62    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>173   </td> <td>388 </td> <td>239  </td> <td>129.04</td> <td>133.33 </td> <td>4.29      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>157   </td> <td>370 </td> <td>168  </td> <td>85.41 </td> <td>81.28  </td> <td>-4.13     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>160   </td> <td>468 </td> <td>151  </td> <td>67.94 </td> <td>79.26  </td> <td>11.32     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>170   </td> <td>341 </td> <td>96   </td> <td>150.51</td> <td>80.97  </td> <td>-69.54    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>163   </td> <td>453 </td> <td>134  </td> <td>129.88</td> <td>69.24  </td> <td>-60.64    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>175   </td> <td>529 </td> <td>264  </td> <td>87.45 </td> <td>56.48  </td> <td>-30.97    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>185   </td> <td>392 </td> <td>240  </td> <td>149.84</td> <td>106.99 </td> <td>-42.85    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>178   </td> <td>479 </td> <td>216  </td> <td>92.24 </td> <td>73.43  </td> <td>-18.81    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (12 rows omitted)</p>"
      ],
      "text/plain": [
       "height | rad  | chemo | base   | month15 | difference\n",
       "164    | 679  | 180   | 160.57 | 87.77   | -72.8\n",
       "168    | 311  | 180   | 98.24  | 67.62   | -30.62\n",
       "173    | 388  | 239   | 129.04 | 133.33  | 4.29\n",
       "157    | 370  | 168   | 85.41  | 81.28   | -4.13\n",
       "160    | 468  | 151   | 67.94  | 79.26   | 11.32\n",
       "170    | 341  | 96    | 150.51 | 80.97   | -69.54\n",
       "163    | 453  | 134   | 129.88 | 69.24   | -60.64\n",
       "175    | 529  | 264   | 87.45  | 56.48   | -30.97\n",
       "185    | 392  | 240   | 149.84 | 106.99  | -42.85\n",
       "178    | 479  | 216   | 92.24  | 73.43   | -18.81\n",
       "... (12 rows omitted)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hodgkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = hodgkins.num_rows\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The radiation was directed towards each patient's chest area or \"mantle\", to destroy cancer cells in the lymph nodes near that area. Since this could adversely affect the patients' lungs, the researchers measured the health of the patients' lungs both before and after treatment. Each patient received a score, with larger scores corresponding to more healthy lungs. \n",
    "\n",
    "The table records the baseline scores and also the scores 15 months after treatment. The change in score (15 month score minus baseline score) is in the final column. Notice the negative differences: 15 months after treatment, many patients' lungs weren't doing as well as before the treatment. \n",
    "\n",
    "Perhaps not surprisingly, patients with larger baseline scores had bigger drops in score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hodgkins.scatter('base', 'difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will regress the difference on the baseline score, this time using the Python module `statsmodels` that allows us to easily perform multiple regression as well. You don't have to learn the code below (though it's not hard). Just focus on understanding an interpreting the output.\n",
    "\n",
    "As a first step, we must import the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/statsmodels/api.py:125\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenmod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m genmod\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenmod\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    116\u001b[0m     GEE,\n\u001b[1;32m    117\u001b[0m     GLM,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m     families,\n\u001b[1;32m    124\u001b[0m )\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m graphics\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgofplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProbPlot, qqline, qqplot, qqplot_2samples\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbayes_mi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MI, BayesGaussMI\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/statsmodels/graphics/api.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgofplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m qqplot\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplottools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rainbow\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregressionplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     abline_plot,\n\u001b[1;32m     11\u001b[0m     influence_plot,\n\u001b[1;32m     12\u001b[0m     plot_ccpr,\n\u001b[1;32m     13\u001b[0m     plot_ccpr_grid,\n\u001b[1;32m     14\u001b[0m     plot_fit,\n\u001b[1;32m     15\u001b[0m     plot_leverage_resid2,\n\u001b[1;32m     16\u001b[0m     plot_partregress,\n\u001b[1;32m     17\u001b[0m     plot_partregress_grid,\n\u001b[1;32m     18\u001b[0m     plot_regress_exog,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabline_plot\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeanplot\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mviolinplot\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     43\u001b[0m ]\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/statsmodels/graphics/regressionplots.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenmod\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneralized_linear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GLM\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnonparametric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msmoothers_lowess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lowess\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GLS, OLS, WLS\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msandbox\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredstd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wls_prediction_std\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/statsmodels/nonparametric/smoothers_lowess.py:11\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"Lowess - wrapper for cythonized extension\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mAuthor : Chris Jordan-Squire\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smoothers_lowess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lowess \u001b[38;5;28;01mas\u001b[39;00m _lowess\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlowess\u001b[39m(endog, exog, frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3.0\u001b[39m, it\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, xvals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, is_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m            missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m'\u001b[39m, return_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''LOWESS (Locally Weighted Scatterplot Smoothing)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    A lowess function that outs smoothed estimates of endog\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n",
      "File \u001b[0;32mstatsmodels/nonparametric/_smoothers_lowess.pyx:1\u001b[0m, in \u001b[0;36minit statsmodels.nonparametric._smoothers_lowess\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Table` method `to_df` allows us to convert the table `hodgkins` to a structure called a data frame that works more smoothly with `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>rad</th>\n",
       "      <th>chemo</th>\n",
       "      <th>base</th>\n",
       "      <th>month15</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>679</td>\n",
       "      <td>180</td>\n",
       "      <td>160.57</td>\n",
       "      <td>87.77</td>\n",
       "      <td>-72.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>311</td>\n",
       "      <td>180</td>\n",
       "      <td>98.24</td>\n",
       "      <td>67.62</td>\n",
       "      <td>-30.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>388</td>\n",
       "      <td>239</td>\n",
       "      <td>129.04</td>\n",
       "      <td>133.33</td>\n",
       "      <td>4.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>157</td>\n",
       "      <td>370</td>\n",
       "      <td>168</td>\n",
       "      <td>85.41</td>\n",
       "      <td>81.28</td>\n",
       "      <td>-4.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>468</td>\n",
       "      <td>151</td>\n",
       "      <td>67.94</td>\n",
       "      <td>79.26</td>\n",
       "      <td>11.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>170</td>\n",
       "      <td>341</td>\n",
       "      <td>96</td>\n",
       "      <td>150.51</td>\n",
       "      <td>80.97</td>\n",
       "      <td>-69.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>163</td>\n",
       "      <td>453</td>\n",
       "      <td>134</td>\n",
       "      <td>129.88</td>\n",
       "      <td>69.24</td>\n",
       "      <td>-60.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>175</td>\n",
       "      <td>529</td>\n",
       "      <td>264</td>\n",
       "      <td>87.45</td>\n",
       "      <td>56.48</td>\n",
       "      <td>-30.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>185</td>\n",
       "      <td>392</td>\n",
       "      <td>240</td>\n",
       "      <td>149.84</td>\n",
       "      <td>106.99</td>\n",
       "      <td>-42.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>178</td>\n",
       "      <td>479</td>\n",
       "      <td>216</td>\n",
       "      <td>92.24</td>\n",
       "      <td>73.43</td>\n",
       "      <td>-18.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>179</td>\n",
       "      <td>376</td>\n",
       "      <td>160</td>\n",
       "      <td>117.43</td>\n",
       "      <td>101.61</td>\n",
       "      <td>-15.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>181</td>\n",
       "      <td>539</td>\n",
       "      <td>196</td>\n",
       "      <td>129.75</td>\n",
       "      <td>90.78</td>\n",
       "      <td>-38.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>173</td>\n",
       "      <td>217</td>\n",
       "      <td>204</td>\n",
       "      <td>97.59</td>\n",
       "      <td>76.38</td>\n",
       "      <td>-21.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>166</td>\n",
       "      <td>456</td>\n",
       "      <td>192</td>\n",
       "      <td>81.29</td>\n",
       "      <td>67.66</td>\n",
       "      <td>-13.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>170</td>\n",
       "      <td>252</td>\n",
       "      <td>150</td>\n",
       "      <td>98.29</td>\n",
       "      <td>55.51</td>\n",
       "      <td>-42.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>165</td>\n",
       "      <td>622</td>\n",
       "      <td>162</td>\n",
       "      <td>118.98</td>\n",
       "      <td>90.92</td>\n",
       "      <td>-28.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>173</td>\n",
       "      <td>305</td>\n",
       "      <td>213</td>\n",
       "      <td>103.17</td>\n",
       "      <td>79.74</td>\n",
       "      <td>-23.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>174</td>\n",
       "      <td>566</td>\n",
       "      <td>198</td>\n",
       "      <td>94.97</td>\n",
       "      <td>93.08</td>\n",
       "      <td>-1.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>173</td>\n",
       "      <td>322</td>\n",
       "      <td>119</td>\n",
       "      <td>85.00</td>\n",
       "      <td>41.96</td>\n",
       "      <td>-43.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>173</td>\n",
       "      <td>270</td>\n",
       "      <td>160</td>\n",
       "      <td>115.02</td>\n",
       "      <td>81.12</td>\n",
       "      <td>-33.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>183</td>\n",
       "      <td>259</td>\n",
       "      <td>241</td>\n",
       "      <td>125.02</td>\n",
       "      <td>97.18</td>\n",
       "      <td>-27.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>188</td>\n",
       "      <td>238</td>\n",
       "      <td>252</td>\n",
       "      <td>137.43</td>\n",
       "      <td>113.20</td>\n",
       "      <td>-24.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    height  rad  chemo    base  month15  difference\n",
       "0      164  679    180  160.57    87.77      -72.80\n",
       "1      168  311    180   98.24    67.62      -30.62\n",
       "2      173  388    239  129.04   133.33        4.29\n",
       "3      157  370    168   85.41    81.28       -4.13\n",
       "4      160  468    151   67.94    79.26       11.32\n",
       "5      170  341     96  150.51    80.97      -69.54\n",
       "6      163  453    134  129.88    69.24      -60.64\n",
       "7      175  529    264   87.45    56.48      -30.97\n",
       "8      185  392    240  149.84   106.99      -42.85\n",
       "9      178  479    216   92.24    73.43      -18.81\n",
       "10     179  376    160  117.43   101.61      -15.82\n",
       "11     181  539    196  129.75    90.78      -38.97\n",
       "12     173  217    204   97.59    76.38      -21.21\n",
       "13     166  456    192   81.29    67.66      -13.63\n",
       "14     170  252    150   98.29    55.51      -42.78\n",
       "15     165  622    162  118.98    90.92      -28.06\n",
       "16     173  305    213  103.17    79.74      -23.43\n",
       "17     174  566    198   94.97    93.08       -1.89\n",
       "18     173  322    119   85.00    41.96      -43.04\n",
       "19     173  270    160  115.02    81.12      -33.90\n",
       "20     183  259    241  125.02    97.18      -27.84\n",
       "21     188  238    252  137.43   113.20      -24.23"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_data = hodgkins.to_df()\n",
    "h_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several variables we could use to predict the difference. The only one we wouldn't use is the 15 month measurement, as that's precisely what we won't have for a new patient before the treatment is adminstered. \n",
    "\n",
    "But which of the rest should we use? One way to choose is to look at the *correlation matrix* of all the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>rad</th>\n",
       "      <th>chemo</th>\n",
       "      <th>base</th>\n",
       "      <th>month15</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>height</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.305206</td>\n",
       "      <td>0.576825</td>\n",
       "      <td>0.354229</td>\n",
       "      <td>0.390527</td>\n",
       "      <td>-0.043394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rad</td>\n",
       "      <td>-0.305206</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003739</td>\n",
       "      <td>0.096432</td>\n",
       "      <td>0.040616</td>\n",
       "      <td>-0.073453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chemo</td>\n",
       "      <td>0.576825</td>\n",
       "      <td>-0.003739</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062187</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.346310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>base</td>\n",
       "      <td>0.354229</td>\n",
       "      <td>0.096432</td>\n",
       "      <td>0.062187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.561371</td>\n",
       "      <td>-0.630183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>month15</td>\n",
       "      <td>0.390527</td>\n",
       "      <td>0.040616</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.561371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.288794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>difference</td>\n",
       "      <td>-0.043394</td>\n",
       "      <td>-0.073453</td>\n",
       "      <td>0.346310</td>\n",
       "      <td>-0.630183</td>\n",
       "      <td>0.288794</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              height       rad     chemo      base   month15  difference\n",
       "height      1.000000 -0.305206  0.576825  0.354229  0.390527   -0.043394\n",
       "rad        -0.305206  1.000000 -0.003739  0.096432  0.040616   -0.073453\n",
       "chemo       0.576825 -0.003739  1.000000  0.062187  0.445788    0.346310\n",
       "base        0.354229  0.096432  0.062187  1.000000  0.561371   -0.630183\n",
       "month15     0.390527  0.040616  0.445788  0.561371  1.000000    0.288794\n",
       "difference -0.043394 -0.073453  0.346310 -0.630183  0.288794    1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry in this table is the correlation between the variable specified by the row label and the variable specified by the column label. That's why all the diagonal entries are $1$.\n",
    "\n",
    "Look at the last column (or last row). This contains the correlation between `difference` and each of the other variables. The baseline measurement has the largest correlation. To run the regression of `difference` on `base` we must first extract the columns of data that we need and then use the appropriate `statsmodels` methods.\n",
    "\n",
    "First, we create data frames corresponding to the response and the predictor variable. The methods are not the same as for `Tables`, but you will get a general sense of what they are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = h_data[['difference']]  # response\n",
    "x = h_data[['base']]        # predictor\n",
    "\n",
    "# specify that the model includes an intercept\n",
    "x_with_int = sm.add_constant(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name of the `OLS` method stands for Ordinary Least Squares, which is the kind of least squares that we have discussed. There are other more complicated kinds that you might encounter in more advanced classes.\n",
    "\n",
    "There is a lot of output, some of which we will discuss and the rest of which we will leave to another class. For some reason the output includes the date and time of running the regression, right in the middle of the summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>difference</td>    <th>  R-squared:         </th> <td>   0.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.367</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   13.17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 06 Dec 2019</td> <th>  Prob (F-statistic):</th>  <td>0.00167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:34:07</td>     <th>  Log-Likelihood:    </th> <td> -92.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    22</td>      <th>  AIC:               </th> <td>   189.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    20</td>      <th>  BIC:               </th> <td>   192.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   32.1721</td> <td>   17.151</td> <td>    1.876</td> <td> 0.075</td> <td>   -3.604</td> <td>   67.949</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>base</th>  <td>   -0.5447</td> <td>    0.150</td> <td>   -3.630</td> <td> 0.002</td> <td>   -0.858</td> <td>   -0.232</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.133</td> <th>  Durbin-Watson:     </th> <td>   1.774</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.568</td> <th>  Jarque-Bera (JB):  </th> <td>   0.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.362</td> <th>  Prob(JB):          </th> <td>   0.785</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.069</td> <th>  Cond. No.          </th> <td>    530.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             difference   R-squared:                       0.397\n",
       "Model:                            OLS   Adj. R-squared:                  0.367\n",
       "Method:                 Least Squares   F-statistic:                     13.17\n",
       "Date:                Fri, 06 Dec 2019   Prob (F-statistic):            0.00167\n",
       "Time:                        22:34:07   Log-Likelihood:                -92.947\n",
       "No. Observations:                  22   AIC:                             189.9\n",
       "Df Residuals:                      20   BIC:                             192.1\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         32.1721     17.151      1.876      0.075      -3.604      67.949\n",
       "base          -0.5447      0.150     -3.630      0.002      -0.858      -0.232\n",
       "==============================================================================\n",
       "Omnibus:                        1.133   Durbin-Watson:                   1.774\n",
       "Prob(Omnibus):                  0.568   Jarque-Bera (JB):                0.484\n",
       "Skew:                           0.362   Prob(JB):                        0.785\n",
       "Kurtosis:                       3.069   Cond. No.                         530.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_regression = sm.OLS(y, x_with_int).fit()\n",
    "simple_regression.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three blocks of output. We will focus only on the the middle block.\n",
    "\n",
    "- `const` and `base` refer to the intercept and baseline measurement.\n",
    "- `coef` stands for the estimated coefficients, which in our notation are $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$.\n",
    "- `t` is the $t$-statistic for testing whether or not the coefficient is 0. Based on our model, its degrees of freedom are $n-2 = 20$; you'll find this under `Df Residuals` in the top block.\n",
    "- `P > |t|` is the total area in the two tails of the $t$ distribution with $n-2$ degrees of freedom.\n",
    "- `[0.025 0.975]` are the ends of a 95% confidence interval for the parameter.\n",
    "\n",
    "For the test of whether or not the true slope of the baseline measurement is $0$, the observed test statistic is\n",
    "\n",
    "$$\n",
    "\\frac{-0.5447 - 0}{0.150} ~ = ~ -3.63\n",
    "$$\n",
    "\n",
    "The area in one tail is the chance that the $t$ distribution with $20$ degrees of freedom is less than $-3.63$. That's the cdf of the distribution evaluated at $-3.63$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008339581409629714"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_tail = stats.t.cdf(-3.63, 20)\n",
    "one_tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test is two-sided (large values of $\\vert t \\vert$ favor the alternative), so the $p$-value of the test is the total area of two tails, which is the displayed value $0.002$ after rounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0016679162819259429"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 2*one_tail\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a 95% confidence interval for the true slope, we have to replace $2$ in the expression $\\hat{\\beta}_1 \\pm 2SE(\\hat{\\beta}_1)$ by the corresponding value from the $t$ distribution with 20 degrees of freedom. That's not very far from $2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0859634472658364"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_95 = stats.t.ppf(0.975, 20)\n",
    "t_95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 95% confidence interval for the true slope is given by $\\hat{\\beta}_1 \\pm t_{95}SE(\\hat{\\beta}_1)$. The observed interval is therefore given by the calculation below, which results in the same values as in the output of `sm.OLS` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.8575945170898753, -0.23180548291012454)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 95% confidence interval for the true slope\n",
    "\n",
    "-0.5447 - t_95*0.150, -0.5447 + t_95*0.150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Regression ###\n",
    "What if we wanted to regress `difference` on both `base` and `chemo`? The first thing to do would be to check the correlation matrix again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>rad</th>\n",
       "      <th>chemo</th>\n",
       "      <th>base</th>\n",
       "      <th>month15</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>height</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.305206</td>\n",
       "      <td>0.576825</td>\n",
       "      <td>0.354229</td>\n",
       "      <td>0.390527</td>\n",
       "      <td>-0.043394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rad</td>\n",
       "      <td>-0.305206</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003739</td>\n",
       "      <td>0.096432</td>\n",
       "      <td>0.040616</td>\n",
       "      <td>-0.073453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chemo</td>\n",
       "      <td>0.576825</td>\n",
       "      <td>-0.003739</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062187</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.346310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>base</td>\n",
       "      <td>0.354229</td>\n",
       "      <td>0.096432</td>\n",
       "      <td>0.062187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.561371</td>\n",
       "      <td>-0.630183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>month15</td>\n",
       "      <td>0.390527</td>\n",
       "      <td>0.040616</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.561371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.288794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>difference</td>\n",
       "      <td>-0.043394</td>\n",
       "      <td>-0.073453</td>\n",
       "      <td>0.346310</td>\n",
       "      <td>-0.630183</td>\n",
       "      <td>0.288794</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              height       rad     chemo      base   month15  difference\n",
       "height      1.000000 -0.305206  0.576825  0.354229  0.390527   -0.043394\n",
       "rad        -0.305206  1.000000 -0.003739  0.096432  0.040616   -0.073453\n",
       "chemo       0.576825 -0.003739  1.000000  0.062187  0.445788    0.346310\n",
       "base        0.354229  0.096432  0.062187  1.000000  0.561371   -0.630183\n",
       "month15     0.390527  0.040616  0.445788  0.561371  1.000000    0.288794\n",
       "difference -0.043394 -0.073453  0.346310 -0.630183  0.288794    1.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you are looking for is not just that `chemo` is the next most highly correlated with `difference` after `base`. More importantly, you are looking to see how strongly the two predictor variables `base` and `chemo` are linearly related *to each other*. That is, you are trying to figure out whether the two variables pick up genuinely different dimensions of the data.\n",
    "\n",
    "The correlation matrix shows that the correlation between `base` and `chemo` is only about $0.06$. The two predictors are not close to being linear functions of each other. So let's run the regression.\n",
    "\n",
    "The code is exactly the same as before, except that we have included a second predictor variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>difference</td>    <th>  R-squared:         </th> <td>   0.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 06 Dec 2019</td> <th>  Prob (F-statistic):</th> <td>0.000548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:34:31</td>     <th>  Log-Likelihood:    </th> <td> -89.820</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    22</td>      <th>  AIC:               </th> <td>   185.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    19</td>      <th>  BIC:               </th> <td>   188.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.9992</td> <td>   20.227</td> <td>   -0.049</td> <td> 0.961</td> <td>  -43.335</td> <td>   41.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>base</th>  <td>   -0.5655</td> <td>    0.134</td> <td>   -4.226</td> <td> 0.000</td> <td>   -0.846</td> <td>   -0.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chemo</th> <td>    0.1898</td> <td>    0.076</td> <td>    2.500</td> <td> 0.022</td> <td>    0.031</td> <td>    0.349</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.853</td> <th>  Durbin-Watson:     </th> <td>   1.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.653</td> <th>  Jarque-Bera (JB):  </th> <td>   0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.317</td> <th>  Prob(JB):          </th> <td>   0.832</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.987</td> <th>  Cond. No.          </th> <td>1.36e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.36e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             difference   R-squared:                       0.546\n",
       "Model:                            OLS   Adj. R-squared:                  0.499\n",
       "Method:                 Least Squares   F-statistic:                     11.44\n",
       "Date:                Fri, 06 Dec 2019   Prob (F-statistic):           0.000548\n",
       "Time:                        22:34:31   Log-Likelihood:                -89.820\n",
       "No. Observations:                  22   AIC:                             185.6\n",
       "Df Residuals:                      19   BIC:                             188.9\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.9992     20.227     -0.049      0.961     -43.335      41.336\n",
       "base          -0.5655      0.134     -4.226      0.000      -0.846      -0.285\n",
       "chemo          0.1898      0.076      2.500      0.022       0.031       0.349\n",
       "==============================================================================\n",
       "Omnibus:                        0.853   Durbin-Watson:                   1.781\n",
       "Prob(Omnibus):                  0.653   Jarque-Bera (JB):                0.368\n",
       "Skew:                           0.317   Prob(JB):                        0.832\n",
       "Kurtosis:                       2.987   Cond. No.                     1.36e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.36e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = h_data[['difference']]      # response\n",
    "x2 = h_data[['base', 'chemo']]  # predictors\n",
    "\n",
    "# specify that the model includes an intercept\n",
    "x2_with_int = sm.add_constant(x2) \n",
    "\n",
    "multiple_regression = sm.OLS(y, x2_with_int).fit()\n",
    "multiple_regression.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the scary warning above. There isn't strong multicollinearity (predictor variables being highly correlated with each other) nor other serious issues.\n",
    "\n",
    "Just focus on the middle block of the output. It's just like the middle block of the simple regression output, with one more line corresponding to `chemo`.\n",
    "\n",
    "All of the values in the block are interpreted in the same way as before. The only change is in the degrees of freedom: because you are estimating one more parameter, the degrees of freedom have dropped by $1$, and are thus $19$ instead of $20$.\n",
    "\n",
    "For example, the 95% confidence interval for the slope of `chemo` is calculated as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03073017186497201, 0.348869828135028)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_95_df19 = stats.t.ppf(0.975, 19)\n",
    "\n",
    "0.1898 - t_95_df19*0.076, 0.1898 + t_95_df19*0.076"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, take a look at the value of `R-squared` in the very top line. It is $0.546$ compared to $0.397$ for the simple regression. It's a math fact that the more predictor variables you use, the higher the `R-squared` value will be. This tempts people into using lots of predictors, whether or not the resulting model is comprehensible.\n",
    "\n",
    "With an \"everything as well as the kitchen sink\" approach to selecting predictor variables, a researcher might be inclined to use all the possible predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>difference</td>    <th>  R-squared:         </th> <td>   0.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 06 Dec 2019</td> <th>  Prob (F-statistic):</th>  <td>0.00645</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:50:02</td>     <th>  Log-Likelihood:    </th> <td> -89.741</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    22</td>      <th>  AIC:               </th> <td>   189.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    17</td>      <th>  BIC:               </th> <td>   194.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td>   33.5226</td> <td>  101.061</td> <td>    0.332</td> <td> 0.744</td> <td> -179.698</td> <td>  246.743</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>base</th>   <td>   -0.5393</td> <td>    0.160</td> <td>   -3.378</td> <td> 0.004</td> <td>   -0.876</td> <td>   -0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chemo</th>  <td>    0.2124</td> <td>    0.103</td> <td>    2.053</td> <td> 0.056</td> <td>   -0.006</td> <td>    0.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rad</th>    <td>   -0.0062</td> <td>    0.031</td> <td>   -0.203</td> <td> 0.841</td> <td>   -0.071</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>height</th> <td>   -0.2274</td> <td>    0.658</td> <td>   -0.346</td> <td> 0.734</td> <td>   -1.615</td> <td>    1.160</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.589</td> <th>  Durbin-Watson:     </th> <td>   1.812</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.745</td> <th>  Jarque-Bera (JB):  </th> <td>   0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.286</td> <th>  Prob(JB):          </th> <td>   0.852</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.851</td> <th>  Cond. No.          </th> <td>1.46e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.46e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             difference   R-squared:                       0.550\n",
       "Model:                            OLS   Adj. R-squared:                  0.444\n",
       "Method:                 Least Squares   F-statistic:                     5.185\n",
       "Date:                Fri, 06 Dec 2019   Prob (F-statistic):            0.00645\n",
       "Time:                        22:50:02   Log-Likelihood:                -89.741\n",
       "No. Observations:                  22   AIC:                             189.5\n",
       "Df Residuals:                      17   BIC:                             194.9\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         33.5226    101.061      0.332      0.744    -179.698     246.743\n",
       "base          -0.5393      0.160     -3.378      0.004      -0.876      -0.202\n",
       "chemo          0.2124      0.103      2.053      0.056      -0.006       0.431\n",
       "rad           -0.0062      0.031     -0.203      0.841      -0.071       0.059\n",
       "height        -0.2274      0.658     -0.346      0.734      -1.615       1.160\n",
       "==============================================================================\n",
       "Omnibus:                        0.589   Durbin-Watson:                   1.812\n",
       "Prob(Omnibus):                  0.745   Jarque-Bera (JB):                0.321\n",
       "Skew:                           0.286   Prob(JB):                        0.852\n",
       "Kurtosis:                       2.851   Cond. No.                     1.46e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.46e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = h_data[['difference']]      # response\n",
    "x3 = h_data[['base', 'chemo', 'rad', 'height']]  # predictors\n",
    "\n",
    "# specify that the model includes an intercept\n",
    "x3_with_int = sm.add_constant(x3) \n",
    "\n",
    "bad_regression = sm.OLS(y, x3_with_int).fit()\n",
    "bad_regression.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a good idea. We end up with a far more complicated model for no appreciable gain in `R-squared`. The \"adjusted $R^2$\" penalizes us for using more predictor variables: notice that the value of `Adj. R-squared` is smaller for the regression with all the predictors than for the regression with just `base` and `chemo`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious about how to select predictors, or about what makes a good regression? Then take some more statistics classes! This one is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}