
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>11.2. The German Tank Problem, Revisited &#8212; Stat 88 Textbook</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="11.3. Least Squares Linear Regression" href="03_Least_Squares_Linear_Regression.html" />
    <link rel="prev" title="11.1. Bias and Variance" href="01_Bias_and_Variance.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/stat88_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Stat 88 Textbook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_01/00_The_Basics.html">
   1. The Basics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/01_Probabilities_as_Proportions.html">
     1.1. Probabilities as Proportions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/02_Exact_Calculation_or_Bound.html">
     1.2. Exact Calculation, or Bound?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/03_Fundamental_Rules.html">
     1.3. Fundamental Rules
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/04_Exercises.html">
     1.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_02/00_Intersections_and_Conditioning.html">
   2. Intersections and Conditioning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/01_The_Chance_of_an_Intersection.html">
     2.1. The Chance of an Intersection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/02_Symmetry_in_Simple_Random_Sampling.html">
     2.2. Symmetry in Simple Random Sampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/03_Bayes_Rule.html">
     2.3. Bayes’ Rule
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/04_Use_and_Interpretation.html">
     2.4. Use and Interpretation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/05_Independence.html">
     2.5. Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/06_Exercises.html">
     2.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_03/00_Random_Counts.html">
   3. Random Counts
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/01_Success_and_Failure.html">
     3.3. Success and Failure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/02_Random_Variables.html">
     3.4. Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/03_The_Binomial_Distribution.html">
     3.5. The Binomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/04_The_Hypergeometric_Distribution.html">
     3.6. The Hypergeometric Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/05_Examples.html">
     3.7. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/06_Exercises.html">
     3.8. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_04/00_Infinitely_Many_Values.html">
   4. Infinitely Many Values
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/01_Cumulative_Distribution_Function.html">
     4.2. Cumulative Distribution Function (CDF)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/02_Waiting_Times.html">
     4.3. Waiting Times
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/03_Exponential_Approximations.html">
     4.4. Exponential Approximations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/04_The_Poisson_Distribution.html">
     4.5. The Poisson Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/05_Exercises.html">
     4.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_05/00_Expectation.html">
   5. Expectation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/01_Definition.html">
     5.1. Definition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/02_Functions_of_Random_Variables.html">
     5.2. Functions of Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/03_Method_of_Indicators.html">
     5.3. Method of Indicators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/04_Unbiased_Estimators.html">
     5.4. Unbiased Estimators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/05_Conditional_Expectation.html">
     5.5. Conditional Expectation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/06_Expectation_by_Conditioning.html">
     5.6. Expectation by Conditioning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/07_Exercises.html">
     5.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_06/00_Measuring_Variability.html">
   6. Measuring Variability
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/01_Variance_and_Standard_Deviation.html">
     6.1. Variance and Standard Deviation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/02_Simplifying_the_Calculation.html">
     6.2. Simplifying the Calculation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/03_Markovs_Inequality.html">
     6.3. Markov’s Inequality##
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/04_Chebyshevs_Inequality.html">
     6.4. Chebyshev’s Inequality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/05_Exercises.html">
     6.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_07/00_The_Variance_of_a_Sum.html">
   7. The Variance of a Sum
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/01_Sums_of_Independent_Random_Variables.html">
     7.1. Sums of Independent Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/02_Sampling_Without_Replacement.html">
     7.2. Sampling Without Replacement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/03_The_Law_of_Averages.html">
     7.3. The Law of Averages
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/04_Exercises.html">
     7.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_08/00_Central_Limit_Theorem.html">
   8. Central Limit Theorem
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/01_Distribution_of_a_Sample_Sum.html">
     8.1. The Distribution of a Sample Sum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/02_Standard_Normal_Curve.html">
     8.2. Standard Normal Curve
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/03_Normal_Approximation.html">
     8.3. Normal Approximation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/04_How_Large_is_Large.html">
     8.4. How Large is “Large”?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/05_Exercises.html">
     8.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_09/00_Inference.html">
   9. Inference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/01_Testing_Hypotheses.html">
     9.1. Testing Hypotheses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/02_AB_Testing_Fishers_Exact_Test.html">
     9.2. A/B Testing: Fisher’s Exact Test
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/03_Confidence_Intervals_Method.html">
     9.3. Confidence Intervals: Method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/04_Confidence_Intervals_Interpretation.html">
     9.4. Confidence Intervals: Interpretation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/05_Exercises.html">
     9.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_10/00_Probability_Density.html">
   10. Probability Density
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/01_Density.html">
     10.1. Density
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/02_Expectation_and_Variance.html">
     10.2. Expectation and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/03_The_Exponential_Distribution.html">
     10.3. Exponential Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/04_The_Normal_Distribution.html">
     10.4. The Normal Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/05_Exercises.html">
     10.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="00_Bias_Variance_and_Least_Squares.html">
   11. Bias, Variance, and Least Squares
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="01_Bias_and_Variance.html">
     11.1. Bias and Variance
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     11.2. The German Tank Problem, Revisited
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_Least_Squares_Linear_Regression.html">
     11.3. Least Squares Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_Bounds_on_Correlation.html">
     11.4. Bounds on Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05_The_Error_in_Regression.html">
     11.5. The Error in Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06_Exercises.html">
     11.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Chapter_12/00_Inference_in_Regression.html">
   12. Inference in Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/01_The_Simple_Linear_Regression_Model.html">
     12.1. The Simple Linear Regression Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/02_The_Distribution_of_the_Estimated_Slope.html">
     12.2. The Distribution of the Estimated Slope
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/03_Towards_Multiple_Regression.html">
     12.3. Towards Multiple Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/04_Exercises.html">
     12.4. Exercises
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/content/notebooks/Chapter_11/02_German_Tank_Problem_Revisited.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-bias-of-the-sample-maximum">
   11.2.1. The Bias of the Sample Maximum
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-better-estimator">
   11.2.2. A Better Estimator
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#understanding-the-augmented-maximum">
   11.2.3. Understanding the Augmented Maximum
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>The German Tank Problem, Revisited</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-bias-of-the-sample-maximum">
   11.2.1. The Bias of the Sample Maximum
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-better-estimator">
   11.2.2. A Better Estimator
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#understanding-the-augmented-maximum">
   11.2.3. Understanding the Augmented Maximum
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="cell tag_remove_input docutils container">
</div>
<div class="cell tag_remove_input docutils container">
</div>
<section id="the-german-tank-problem-revisited">
<h1><span class="section-number">11.2. </span>The German Tank Problem, Revisited<a class="headerlink" href="#the-german-tank-problem-revisited" title="Permalink to this headline">#</a></h1>
<p>Earlier in the course we examined the <a class="reference external" href="http://stat88.org/textbook/notebooks/Chapter_05/04_Unbiased_Estimators.html#World-War-II-Tanks">German tank problem</a> in which statisticians helped the Allies estimate the number of tanks the Germans were manufacturing in World War II.</p>
<p>In our discussion we had assumed a simpler model than the one the Allies had used. We had started by assuming, as the Allies had, that the tanks were numbered sequentially from 1 through <span class="math notranslate nohighlight">\(N\)</span>. The goal was to estimate <span class="math notranslate nohighlight">\(N\)</span> from the serial numbers on the tanks that were observed. Our model had said that these numbers were like draws <em>with</em> replacement from <span class="math notranslate nohighlight">\(1, 2, 3, \ldots, N\)</span>. But that’s not a great model for serial numbers observed on tanks that have been captured or destroyed.</p>
<p>So we will now assume, as the Allies did, that the serial numbers of the observed tanks are random variables <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_n\)</span> drawn uniformly at random <em>without</em> replacement from <span class="math notranslate nohighlight">\(\{1, 2, 3, \ldots, N\}\)</span>. That is, we have a simple random sample of size <span class="math notranslate nohighlight">\(n\)</span> from the population <span class="math notranslate nohighlight">\(\{1, 2, 3, \ldots, N\}\)</span>, and we have to estimate <span class="math notranslate nohighlight">\(N\)</span>.</p>
<p>By the symmetry of simple random sampling, each <span class="math notranslate nohighlight">\(X_i\)</span> has the same distribution as the others. The distribution is uniform on <span class="math notranslate nohighlight">\(\{1, 2, 3, \ldots, N\}\)</span>, so for each <span class="math notranslate nohighlight">\(i\)</span> we have</p>
<div class="math notranslate nohighlight">
\[
E(X_i) ~ = ~ \frac{N+1}{2} 
\]</div>
<p>Hence if <span class="math notranslate nohighlight">\(\bar{X}\)</span> is the sample average, then</p>
<div class="math notranslate nohighlight">
\[
E(\bar{X}) ~ = ~ \frac{N+1}{2}
\]</div>
<p>This is a linear function of the parameter <span class="math notranslate nohighlight">\(N\)</span>. So by inverting the function (that is, isolating <span class="math notranslate nohighlight">\(N\)</span>), we can construct an unbiased estimator of <span class="math notranslate nohighlight">\(N\)</span>. We have</p>
<div class="math notranslate nohighlight">
\[
N ~ = ~ 2E(\bar{X}) - 1
\]</div>
<p>This is an equality of constants, but we’ll never know <span class="math notranslate nohighlight">\(E(\bar{X})\)</span> because that quantity involves <span class="math notranslate nohighlight">\(N\)</span>  which is exactly what we are trying to estimate. However, by linearity of expectation, the random variable</p>
<div class="math notranslate nohighlight">
\[
T_1 ~ = ~ 2\bar{X} - 1
\]</div>
<p>has expectation <span class="math notranslate nohighlight">\(N\)</span> and hence is an unbiased estimator of <span class="math notranslate nohighlight">\(N\)</span>. It can be calculated based on the sample <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_n\)</span>.</p>
<p>We have called this estimator <span class="math notranslate nohighlight">\(T_1\)</span> because it is the first of several competing estimators of <span class="math notranslate nohighlight">\(N\)</span>.</p>
<p>Another natural estimator of <span class="math notranslate nohighlight">\(N\)</span> is <span class="math notranslate nohighlight">\(T_2 = \max\{X_1, X_2, \ldots, X_n\}\)</span>, the maximum of the observed numbers. This estimator is clearly biased. It is always less than or equal to <span class="math notranslate nohighlight">\(N\)</span>. So on average, it will underestimate <span class="math notranslate nohighlight">\(N\)</span>.</p>
<p>But not by much! The figure below shows the empirical histograms of <span class="math notranslate nohighlight">\(T_1\)</span> and <span class="math notranslate nohighlight">\(T_2\)</span> based on 10,000 repetitions of drawing a simple random sample of size 30 from the integers <span class="math notranslate nohighlight">\(1\)</span> through <span class="math notranslate nohighlight">\(300\)</span> and computing <span class="math notranslate nohighlight">\(T_1\)</span> and <span class="math notranslate nohighlight">\(T_2\)</span> for each sample. You can see that the distribution of the sample maximum <span class="math notranslate nohighlight">\(T_2\)</span> puts a lot of mass just to the left of the population maximum <span class="math notranslate nohighlight">\(300\)</span>.</p>
<div class="cell tag_remove_input docutils container">
<div class="cell_output docutils container">
<img alt="../../../_images/02_German_Tank_Problem_Revisited_4_0.png" src="../../../_images/02_German_Tank_Problem_Revisited_4_0.png" />
</div>
</div>
<p>The blue histogram shows the empirical distribution of <span class="math notranslate nohighlight">\(T_1 = 2\bar{X} - 1\)</span>. It is roughly normal because the distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> is roughly normal: when sampling <span class="math notranslate nohighlight">\(30\)</span> elements out of a population of <span class="math notranslate nohighlight">\(300\)</span>, sampling with and without replacement aren’t very different, so the Central Limit Theorem for i.i.d. sample means implies approximate normality. As the number of captured or destroyed tanks was small relative to the number produced, it is reasonable to assume that <span class="math notranslate nohighlight">\(n\)</span> is quite a bit smaller than <span class="math notranslate nohighlight">\(N\)</span>.</p>
<p>The blue histogram is centered at <span class="math notranslate nohighlight">\(N = 300\)</span>, the value of <span class="math notranslate nohighlight">\(N\)</span> that we chose for the simulation. That is because <span class="math notranslate nohighlight">\(T_1\)</span> is an unbiased estimator of <span class="math notranslate nohighlight">\(N\)</span>.</p>
<p>The gold histogram displays the distribution of <span class="math notranslate nohighlight">\(T_2 = \max\{1, 2, 3, \ldots, N\}\)</span>. It is entirely to the left of <span class="math notranslate nohighlight">\(N = 300\)</span>, confirming our assertion that <span class="math notranslate nohighlight">\(T_2\)</span> underestimates <span class="math notranslate nohighlight">\(N\)</span>. However, the gold histogram is quite a bit narrower than the blue and puts most of its probability very close to the parameter <span class="math notranslate nohighlight">\(N\)</span>. This is a situation in which we might prefer to use the somewhat biased estimator <span class="math notranslate nohighlight">\(T_2\)</span> over the unbiased but widely variable estimator <span class="math notranslate nohighlight">\(T_1\)</span>.</p>
<section id="the-bias-of-the-sample-maximum">
<h2><span class="section-number">11.2.1. </span>The Bias of the Sample Maximum<a class="headerlink" href="#the-bias-of-the-sample-maximum" title="Permalink to this headline">#</a></h2>
<p>To calculate the bias of <span class="math notranslate nohighlight">\(M\)</span>, it helps to imagine a row of <span class="math notranslate nohighlight">\(N\)</span> spots for the serial numbers <span class="math notranslate nohighlight">\(1\)</span> through <span class="math notranslate nohighlight">\(N\)</span>, with marks at the spots corresponding to the observed serial numbers. The visualization below shows an outcome in the case <span class="math notranslate nohighlight">\(N= 20\)</span> and <span class="math notranslate nohighlight">\(n = 3\)</span>.</p>
<p><img alt="gaps" src="../../../_images/all_gaps1.png" /></p>
<ul class="simple">
<li><p>There are <span class="math notranslate nohighlight">\(N = 20\)</span> spots in all.</p></li>
<li><p>From these, we take a simple random sample of size <span class="math notranslate nohighlight">\(n = 3\)</span>. Those are the gold spots.</p></li>
<li><p>The remaining <span class="math notranslate nohighlight">\(N - n = 17\)</span> spots are colored blue.</p></li>
</ul>
<p>The <span class="math notranslate nohighlight">\(n = 3\)</span> sampled spots create <span class="math notranslate nohighlight">\(n+1 = 4\)</span> blue “gaps” between sampled values: one before the leftmost gold spot, two between successive gold spots, and one after the rightmost gold spot that is at position <span class="math notranslate nohighlight">\(M\)</span>.</p>
<p>The key observation is that because of the symmetry of simple random sampling, the lengths of all four gaps have the same distribution. Therefore all four gaps have the same expected length, which we can find by counting blue and gold spots as follows:</p>
<ul class="simple">
<li><p>The gaps are made up of <span class="math notranslate nohighlight">\(N - n = 17\)</span> blue spots.</p></li>
<li><p>Since each of the four gaps has the same expected length, the expected length of a single gap is <span class="math notranslate nohighlight">\(\frac{17}{4}\)</span>.</p></li>
</ul>
<p>In general, when the data are a simple random sample of <span class="math notranslate nohighlight">\(n\)</span> elements out of <span class="math notranslate nohighlight">\(1, 2, 3, \ldots, N\)</span>, then</p>
<div class="math notranslate nohighlight">
\[
\text{expected length of gap} ~ = ~ \frac{N-n}{n+1}
\]</div>
<p>The length of the very last gap (the one after <span class="math notranslate nohighlight">\(M\)</span>) is the random amount by which <span class="math notranslate nohighlight">\(M\)</span> underestimates <span class="math notranslate nohighlight">\(N\)</span>. Let’s call the length of that gap <span class="math notranslate nohighlight">\(G_{n+1}\)</span> since it is the <span class="math notranslate nohighlight">\((n+1)\)</span>th gap starting from the left.</p>
<p>Then <span class="math notranslate nohighlight">\(N = M + G_{n+1}\)</span>. Take expectations on both sides and remember that <span class="math notranslate nohighlight">\(N\)</span> is a constant:</p>
<div class="math notranslate nohighlight">
\[
N ~ = ~ E(M) + E(G_{n+1}) ~ = ~ E(M) + \frac{N-n}{n+1}
\]</div>
<p>So the bias of <span class="math notranslate nohighlight">\(M\)</span> is</p>
<div class="math notranslate nohighlight">
\[
E(M) - N ~ = ~ \frac{-(N-n)}{n+1}
\]</div>
<p>The bias is negative, consistent with our observation that the sample maximum tends to underestimate <span class="math notranslate nohighlight">\(N\)</span>.</p>
</section>
<section id="a-better-estimator">
<h2><span class="section-number">11.2.2. </span>A Better Estimator<a class="headerlink" href="#a-better-estimator" title="Permalink to this headline">#</a></h2>
<p>The fact that the bias of <span class="math notranslate nohighlight">\(M\)</span> is linear in the parameter <span class="math notranslate nohighlight">\(N\)</span> allows us to construct a new unbiased estimator of <span class="math notranslate nohighlight">\(N\)</span>.</p>
<p>You can of course find <span class="math notranslate nohighlight">\(E(M)\)</span> by using the formula for the bias, but we will find <span class="math notranslate nohighlight">\(E(M)\)</span> by counting spots from the left, up to and including the gold spot at position <span class="math notranslate nohighlight">\(M\)</span>. These spots consist of:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n\)</span> blue gaps of expected length <span class="math notranslate nohighlight">\(\frac{N-n}{n+1}\)</span> each, and</p></li>
<li><p><span class="math notranslate nohighlight">\(n\)</span> gold spots</p></li>
</ul>
<p>Hence</p>
<div class="math notranslate nohighlight">
\[
E(M) ~ = ~ n\big{(}\frac{N-n}{n+1}\big{)} + n ~ = ~ \frac{n}{n+1}(N + 1)
\]</div>
<p>after a little algebra.</p>
<p>This is a linear function of <span class="math notranslate nohighlight">\(N\)</span>, so you can isolate <span class="math notranslate nohighlight">\(N\)</span> to create an unbiased estimator of <span class="math notranslate nohighlight">\(N\)</span> just as we did earlier in the section. Isolating <span class="math notranslate nohighlight">\(N\)</span> gives</p>
<div class="math notranslate nohighlight">
\[
N ~ = ~ E(M)\big{(}\frac{n+1}{n}\big{)} - 1
\]</div>
<p>and so it follows that</p>
<div class="math notranslate nohighlight">
\[
T_3 ~ = ~  M\big{(}\frac{n+1}{n}\big{)} - 1
\]</div>
<p>is an unbiased estimator of <span class="math notranslate nohighlight">\(N\)</span>. We will call this the “augmented maximum” for reasons that will become clear at the end of this section.</p>
<p>Since <span class="math notranslate nohighlight">\(T_3\)</span> is a linear function of <span class="math notranslate nohighlight">\(M\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[
SD(T_3) ~ = ~ \frac{n+1}{n}SD(M) ~ &gt; ~ SD(M)
\]</div>
<p>While <span class="math notranslate nohighlight">\(T_3\)</span> is unbiased and <span class="math notranslate nohighlight">\(M\)</span> is biased, <span class="math notranslate nohighlight">\(T_3\)</span> is more variable than <span class="math notranslate nohighlight">\(M\)</span>.</p>
<p>To decide which one to use, notice that <span class="math notranslate nohighlight">\(SD(T_3) = (1 + \frac{1}{n})SD(M)\)</span>, so the two SDs are almost the same for large <span class="math notranslate nohighlight">\(n\)</span>. For moderate <span class="math notranslate nohighlight">\(n\)</span>, the Allied statisticians decided that the reduction in bias was worth the slight increase in variance.</p>
<p>The simulation below gives you a sense of the relative sizes of all these quantities. The parameter <span class="math notranslate nohighlight">\(N\)</span> and the sample size <span class="math notranslate nohighlight">\(n\)</span> are the same as in the simulation shown earlier in the section.</p>
<div class="cell tag_remove_input docutils container">
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average of Augmented Maxes: 300.04844
SD of of Augmented Maxes: 9.09769437274
Average of Maxes: 291.3372
SD of Maxes: 8.80422036071
</pre></div>
</div>
<img alt="../../../_images/02_German_Tank_Problem_Revisited_8_1.png" src="../../../_images/02_German_Tank_Problem_Revisited_8_1.png" />
</div>
</div>
</section>
<section id="understanding-the-augmented-maximum">
<h2><span class="section-number">11.2.3. </span>Understanding the Augmented Maximum<a class="headerlink" href="#understanding-the-augmented-maximum" title="Permalink to this headline">#</a></h2>
<p>We gave an algebraic derivation of the augmented maximum <span class="math notranslate nohighlight">\(T_3\)</span>, but there is another good way to understand the formula.</p>
<p>The reason the sample maximum <span class="math notranslate nohighlight">\(M\)</span> is biased is that in the sample we can see all but the last gap, as in the figure below in the case <span class="math notranslate nohighlight">\(n = 3\)</span>. The red question mark reminds you that the gap to the right of <span class="math notranslate nohighlight">\(M\)</span> is invisible to us.</p>
<p><img alt="mystery gap" src="../../../_images/mystery_gap1.png" /></p>
<p>If we could see the gap to the right of <span class="math notranslate nohighlight">\(M\)</span>, we would see <span class="math notranslate nohighlight">\(N\)</span>. But we can’t. So we can try to do the next best thing, which is to augment <span class="math notranslate nohighlight">\(M\)</span> by the estimated size of that gap.</p>
<p>Since we can see all of the spots and their colors up to and including <span class="math notranslate nohighlight">\(M\)</span>, we can see <span class="math notranslate nohighlight">\(n\)</span> out of the <span class="math notranslate nohighlight">\(n+1\)</span> gaps. The lengths of the gaps all have the same distribution by symmetry, so we can estimate the length of a single gap by the average length of all the gaps that we can see.</p>
<p>We can see <span class="math notranslate nohighlight">\(M\)</span> spots, of which <span class="math notranslate nohighlight">\(n\)</span> are the sampled values. So the total length of all <span class="math notranslate nohighlight">\(n\)</span> visible gaps is <span class="math notranslate nohighlight">\(M-n\)</span>. Therefore</p>
<div class="math notranslate nohighlight">
\[
\text{estimated length of one gap} ~ = ~ \frac{M-n}{n}
\]</div>
<p>and hence we can try to improve upon <span class="math notranslate nohighlight">\(M\)</span> using the estimator</p>
<div class="math notranslate nohighlight">
\[
M + \frac{M-n}{n}
\]</div>
<p>instead. Now</p>
<div class="math notranslate nohighlight">
\[
M + \frac{M-n}{n} ~ = ~ M\big{(}\frac{n+1}{n}\big{)} - 1 ~ = T_3
\]</div>
<p>Our new estimator is the same as the unbiased estimator <span class="math notranslate nohighlight">\(T_3\)</span> we derived earlier. That is why we have called <span class="math notranslate nohighlight">\(T_3\)</span> the augmented maximum: it is the sample maximum plus one estimated gap.</p>
<p>It is possible for the augmented maximum to overestimate <span class="math notranslate nohighlight">\(N\)</span>. For example, if the observed value of <span class="math notranslate nohighlight">\(M\)</span> happens to be <span class="math notranslate nohighlight">\(N\)</span>, in the calculation of <span class="math notranslate nohighlight">\(T_3\)</span> we will have added a gap that we didn’t need to add and therefore we will overestimate <span class="math notranslate nohighlight">\(N\)</span>.</p>
<p>As before, it is possible for the augmented maximum to underestimate <span class="math notranslate nohighlight">\(N\)</span>, for example if all the sampled serial numbers are small.</p>
<p>What we have shown is that on average, the augmented maximum gets the answer right, and is only slightly more variable than the maximum.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/notebooks/Chapter_11"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="01_Bias_and_Variance.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">11.1. </span>Bias and Variance</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="03_Least_Squares_Linear_Regression.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">11.3. </span>Least Squares Linear Regression</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ani Adhikari<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>